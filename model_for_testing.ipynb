{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95049aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_AUC_ROC(df, show_plot=True):\n",
    "    HC_edits = df[df['edited'] == 1]['prediction'].values\n",
    "    HC_original = df[df['edited'] == 0]['prediction'].values\n",
    "    \n",
    "    y_test = [1 for _ in range(len(HC_edits))] + [0 for _ in range(len(HC_original))]\n",
    "    y_prob = list(HC_edits) + list(HC_original)\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    \n",
    "    # Find the index of the point on the ROC curve closest to (0, 1)\n",
    "    best_threshold_index = np.argmax(tpr - fpr)\n",
    "\n",
    "    # Get the threshold corresponding to the point on the ROC curve\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "    \n",
    "    if show_plot:\n",
    "        # Calculate the AUC-ROC score\n",
    "        auc_roc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_roc:.2f} Threshold = {best_threshold:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "def check_results(df):\n",
    "    if 'edited' not in df.columns:\n",
    "        raise RuntimeError('Column \"edited\" is missing')\n",
    "        \n",
    "    if 'prediction' not in df.columns:\n",
    "        raise RuntimeError('Column \"prediction\" is missing')\n",
    "        \n",
    "    y_true = df['edited'].values.astype('int')\n",
    "    y_pred = df['prediction'].values.astype('int')\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fp = conf_matrix[0, 1]\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fn = conf_matrix[1, 0]\n",
    "    tp = conf_matrix[1, 1]\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"FPR:\", fpr)\n",
    "    print(\"FNR:\", fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64414f26",
   "metadata": {},
   "source": [
    "#### **SVM(word counts + tfidf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ececac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read article from the json string\n",
    "def get_text_article(article_str, get_edits=False, edit_ratio=None, save_number_sentences=False):\n",
    "    text = ''\n",
    "    number_of_sentences = article_str.count('sentence\":')\n",
    "    article_obj = eval(article_str)\n",
    "    if edit_ratio is not None:\n",
    "        num_of_edits = number_of_sentences * edit_ratio // 1\n",
    "    else:\n",
    "        num_of_edits = article_str.count('alternative\":')\n",
    "                \n",
    "    for sub_title in article_obj['sub_titles']:\n",
    "        for sentence in sub_title['sentences']:\n",
    "            current_text = f\"{sentence['sentence']}\\n\"\n",
    "            if get_edits and num_of_edits > 0 and 'alternative' in sentence:\n",
    "                if save_number_sentences: # If save the number of sentences as the original article\n",
    "                    current_text = f\"{sentence['alternative']}\\n\"\n",
    "                else:\n",
    "                    current_text += f\"{sentence['alternative']}\\n\"\n",
    "                num_of_edits -= 1\n",
    "            text += current_text\n",
    "    return text\n",
    "\n",
    "def get_articles_text_lst(df):\n",
    "    article_text_lst = []\n",
    "    article_label_lst = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        article_obj = eval(df.iloc[i]['article_json'])\n",
    "        for edited in [False, True]:\n",
    "            article_text_lst.append(get_text_article(article_obj, edited))\n",
    "            article_label_lst.append(int(edited))\n",
    "    \n",
    "    return article_text_lst, article_label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed7d9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations_articles\n",
      "Train accuracy 0.5\n",
      "Test accuracy 0.5\n",
      "Test accuracy FPR@0.05 0.5\n"
     ]
    }
   ],
   "source": [
    "#train SVM on combined dataset\n",
    "number_of_sentences =200\n",
    "edit_ratio = 0.1\n",
    "\n",
    "topics = ['locations_articles']#'AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}'\n",
    "    \n",
    "    df_train = pd.read_csv(f'{files_path}\\\\{topic}_null.csv').sample(frac=1)\n",
    "    df_validation = df_train[int(len(df_train) * 0.8 // 1):]\n",
    "    df_train = df_train[:int(len(df_train) * 0.8 // 1)]\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\{topic}_test.csv')\n",
    "    \n",
    "    X_train, y_train = get_articles_text_lst(df_train)\n",
    "    X_val  , y_val = get_articles_text_lst(df_validation)\n",
    "    X_test , y_test = get_articles_text_lst(df_test)\n",
    "    \n",
    "    best_model = SVC(C=0.1, gamma=1, kernel='poly', probability=True, random_state=555)\n",
    "    pipe = Pipeline([('count', CountVectorizer(stop_words='english', max_df=0.75, min_df=5, max_features=10000, ngram_range=(1, 2))),\n",
    "                     ('tfid', TfidfTransformer())]).fit(X_train)\n",
    "\n",
    "    X_train = pipe.transform(X_train).toarray()\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    y_train = y_train\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = best_model.predict(X_train)\n",
    "    print(f'Train accuracy {accuracy_score(y_train, pred)}')\n",
    "    \n",
    "    # Get best threshold for the validation set\n",
    "    X_val = pipe.transform(X_val).toarray()\n",
    "    X_val = StandardScaler().fit_transform(X_val)\n",
    "    y_pred = best_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    X_test = pipe.transform(X_test).toarray()\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    y_pred = best_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0789aed",
   "metadata": {},
   "source": [
    "#### **embedding-3-small**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a17602b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_l2(x):\n",
    "    x = np.array(x)\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm(x)\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm(x, 2, axis=1, keepdims=True)\n",
    "        return np.where(norm == 0, x, x / norm)\n",
    "    \n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def create_df_embedding(file_path, embedding_size=370, get_edits=False, edit_ratio=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    client = OpenAI(api_key='XXXXXXXXX')\n",
    "    columns = ['article_index'] + [f'dim_{i+1}' for i in range(embedding_size)]\n",
    "    embedding_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in tqdm(range(len(df))):\n",
    "        article_str = df.iloc[i]['article_json']\n",
    "        article_text = get_text_article(article_str, get_edits, edit_ratio, save_number_sentences=True) #save_number_sentences=True\n",
    "\n",
    "        # Max token\n",
    "        if num_tokens_from_string(article_text, \"cl100k_base\") > 8191:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            response = client.embeddings.create(model=\"text-embedding-3-small\", input=article_text, encoding_format=\"float\")\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        cut_dim = response.data[0].embedding[:embedding_size]\n",
    "        norm_dim = normalize_l2(cut_dim)\n",
    "\n",
    "        embedding_df = pd.concat([embedding_df, pd.DataFrame([[i] + list(norm_dim)], columns=columns)])\n",
    "        \n",
    "    return embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92a89256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.05 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:53<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.05 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:55<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:58<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:54<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.15 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:51<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.15 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 183/183 [01:45<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.05 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:48<00:00,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.05 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:53<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:51<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:54<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.15 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:51<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.15 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 195/195 [01:54<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create embedded data main dataset\n",
    "edit_ratios = [0.05, 0.1, 0.15]\n",
    "topics = ['video_games_series_movies_articles', 'war_articles'] #'characters_articles', 'locations_articles', 'nature_articles', \n",
    "has_edits = [False, True]\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        for get_edits in has_edits:\n",
    "            print(f'topic: {topic} edit_ratio: {edit_ratio} get_edits: {get_edits}')\n",
    "            suffix = 'edited' if get_edits else 'not_edited'\n",
    "            file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\{topic}.csv'\n",
    "            dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\{topic}_embedded_{suffix}.csv'\n",
    "\n",
    "            embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits, edit_ratio=None)\n",
    "            embedding_df.to_csv(dest_path)\n",
    "            \n",
    "#             file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\{topic}_test.csv'\n",
    "#             dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\{topic}_test_embedded_{suffix}.csv'\n",
    "\n",
    "#             embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits, edit_ratio=None)\n",
    "#             embedding_df.to_csv(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5ec5f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [01:13<00:00,  1.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [01:30<00:00,  1.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [02:57<00:00,  1.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [02:39<00:00,  1.32s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [01:16<00:00,  1.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [00:59<00:00,  2.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [00:53<00:00,  1.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [05:54<00:00,  4.38s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [02:41<00:00,  1.99s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [00:52<00:00,  1.53it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [16:58<00:00, 12.58s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [01:07<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create embedding small data\n",
    "for file_type in ['null', 'test']:\n",
    "    for get_edits in [True, False]:\n",
    "        for edit_ratio in [0.05, 0.1, 0.15]: \n",
    "            suffix = 'edited' if get_edits else 'not_edited'\n",
    "            file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_{edit_ratio}\\\\test_somthing\\\\{file_type}_data_chars.csv'\n",
    "            dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_{edit_ratio}\\\\test_somthing\\\\{file_type}_data_chars_embedded_{suffix}.csv'\n",
    "\n",
    "            embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits, edit_ratio=None)\n",
    "            embedding_df.to_csv(dest_path)\n",
    "            \n",
    "for edit_ratio in [0.05, 0.1, 0.15]: \n",
    "    for file_type in ['null', 'test']:\n",
    "        df_lst = []\n",
    "        for i, get_edits in enumerate([False, True]):\n",
    "            suffix = 'edited' if get_edits else 'not_edited'\n",
    "            dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_{edit_ratio}\\\\test_somthing\\\\{file_type}_data_chars_embedded_{suffix}.csv'\n",
    "            temp_df = pd.read_csv(dest_path)\n",
    "            temp_df['has_edits'] = i # not edited = 0 edit = 1\n",
    "            df_lst.append(temp_df)\n",
    "        df = pd.concat(df_lst, ignore_index=True)\n",
    "        df.to_csv(f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_{edit_ratio}\\\\test_somthing\\\\{file_type}_data_chars_embedded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32395c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedded data second dataset\n",
    "edit_ratios = [10] #, 20\n",
    "num_of_sentences = [200] #50, 100, \n",
    "topics = ['AbstractDataset'] #'WikiDataset', 'NewsDataset', \n",
    "has_edits = [False, True]\n",
    "\n",
    "for topic in topics:\n",
    "    for num in num_of_sentences:\n",
    "        for edit_ratio in edit_ratios:\n",
    "            for get_edits in has_edits:\n",
    "                print(f'topic: {topic} edit_ratio: {edit_ratio} get_edits: {get_edits}')\n",
    "                suffix = 'edited' if get_edits else 'not_edited'\n",
    "                \n",
    "                file_name = 'model_name_Research_Abstracts_null';\n",
    "                file_name = 'model_name_news_articles_null' if topic == 'NewsDataset' else file_name\n",
    "                file_name = 'model_name_wiki_intro_null' if topic == 'WikiDataset' else file_name\n",
    "                \n",
    "                \n",
    "                file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}.csv'\n",
    "                dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}_embedded_{suffix}.csv'\n",
    "\n",
    "                embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits)\n",
    "                embedding_df.to_csv(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61891489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the files\n",
    "edit_ratios = [20] #, 20\n",
    "num_of_sentences = [200] #, 100, 200\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset'] # \n",
    "has_edits = [False, True]\n",
    "df = None\n",
    "for topic in topics:\n",
    "    for num in num_of_sentences:\n",
    "        for edit_ratio in edit_ratios:\n",
    "            for get_edits in has_edits:\n",
    "                suffix = 'edited' if get_edits else 'not_edited'\n",
    "                \n",
    "                file_name = 'model_name_Research_Abstracts_null';\n",
    "                file_name = 'model_name_news_articles_null' if topic == 'NewsDataset' else file_name\n",
    "                file_name = 'model_name_wiki_intro_null' if topic == 'WikiDataset' else file_name\n",
    "                \n",
    "                file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}_embedded_{suffix}.csv'\n",
    "                if df is None:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    df = pd.concat([df, pd.read_csv(file_path)])\n",
    "\n",
    "dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{num_of_sentences[0]}_sentences\\\\{edit_ratios[0]}'\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv(f'{dest_path}\\\\model_name_combined_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7c39115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(file_name_train, file_name_test):\n",
    "    df_not_edited = pd.read_csv(f'{file_name_train}_embedded_not_edited.csv')\n",
    "    df_edited = pd.read_csv(f'{file_name_train}_embedded_edited.csv')\n",
    "\n",
    "    df_not_edited.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_edited.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df = pd.concat([df_not_edited, df_edited])\n",
    "    df['y'] = [0 for _ in range(len(df_not_edited))] + [1 for _ in range(len(df_edited))]\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    df_not_edited_test = pd.read_csv(f'{file_name_test}_embedded_not_edited.csv')\n",
    "    df_edited_test = pd.read_csv(f'{file_name_test}_embedded_edited.csv')\n",
    "\n",
    "    df_not_edited_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_edited_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df_test = pd.concat([df_not_edited_test, df_edited_test])\n",
    "    df_test['y'] = [0 for _ in range(len(df_not_edited_test))] + [1 for _ in range(len(df_edited_test))]\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b96c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threhsold_at_FPR(y_test, y_prob, threshold_FPR_at, steps=0.01):\n",
    "    # Find the threshold for FPR = threshold_FPR_at\n",
    "    min_dist_type = y_prob.min()\n",
    "    max_dist_type = y_prob.max()\n",
    "    best_threshold = max_dist_type\n",
    "    best_acc = 0\n",
    "    \n",
    "    for threshold in np.arange(min_dist_type, max_dist_type, steps):\n",
    "        y_score = (y_prob >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_score).ravel()\n",
    "        TPR = fp / (fp + tn)\n",
    "        if TPR <= threshold_FPR_at:\n",
    "            acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_threshold = threshold \n",
    "            \n",
    "    return best_threshold\n",
    "\n",
    "def find_threhsold_best_accuracy(y_test, y_prob, threshold_FPR_at, steps=0.01):\n",
    "    # Find the threshold for FPR = threshold_FPR_at\n",
    "    min_dist_type = y_prob.min()\n",
    "    max_dist_type = y_prob.max()\n",
    "    best_threshold = max_dist_type\n",
    "    best_acc = 0\n",
    "    \n",
    "    for threshold in np.arange(min_dist_type, max_dist_type, steps):\n",
    "        y_score = (y_prob >= threshold).astype(int)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_score).ravel()\n",
    "        acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold \n",
    "            \n",
    "    return best_threshold\n",
    "\n",
    "def check_AUC_ROC(y_test, y_prob, title='', dist_type='HC', show_plot=False, threshold_FPR_at=None, steps=0.01):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    if threshold_FPR_at == None:\n",
    "        # Find the index of the point on the ROC curve closest to (0, 1)\n",
    "        best_threshold_index = np.argmax(tpr - fpr)\n",
    "        # Get the threshold corresponding to the point on the ROC curve\n",
    "        best_threshold = thresholds[best_threshold_index]\n",
    "    elif threshold_FPR_at == -1:\n",
    "        best_threshold = find_threhsold_best_accuracy(y_test, y_prob, threshold_FPR_at, steps=steps)\n",
    "    else:\n",
    "        best_threshold = find_threhsold_at_FPR(y_test, y_prob, threshold_FPR_at, steps=steps)\n",
    "    \n",
    "    # Calculate the AUC-ROC score\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    if show_plot:\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_roc:.2f} Threshold = {best_threshold:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title(f'Receiver Operating Characteristic (ROC) Curve on {dist_type} \\n{title}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    return best_threshold, auc_roc\n",
    "\n",
    "def get_AUC(df, dist_type='HC', label='edited'):\n",
    "    HC_edits = df[df[label] == 1][dist_type].values\n",
    "    HC_original = df[df[label] == 0][dist_type].values\n",
    "\n",
    "    y_test = [1 for _ in range(len(HC_edits))] + [0 for _ in range(len(HC_original))]\n",
    "    y_prob = list(HC_edits) + list(HC_original)\n",
    "    \n",
    "    NaN_list = []\n",
    "    # Check for NaN\n",
    "    for i, v in enumerate(y_prob):\n",
    "        if np.isnan(v):\n",
    "            NaN_list.append(i)\n",
    "            \n",
    "    for i in NaN_list:\n",
    "        y_test.pop(i)\n",
    "        y_prob.pop(i)\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    return auc_roc\n",
    "\n",
    "def calculate_fpr(y, pred):\n",
    "    # Calculate True Negatives (TN) and False Positives (FP)\n",
    "    tn = np.sum((y == 0) & (pred == 0))\n",
    "    fp = np.sum((y == 0) & (pred == 1))\n",
    "    \n",
    "    # Calculate False Positive Rate\n",
    "    fpr = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "    return fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "990232f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best hyperparameters: {'C': 100, 'gamma': 1, 'kernel': 'linear'}\n",
      "AUC 0.8165007112375533\n",
      "Test accuracy 0.7567567567567568 FPR@0.32432432432432434\n",
      "Test accuracy 0.6216216216216216 FPR@0.05\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search for hyper parameters\n",
    "RANDOM_STATE=555\n",
    "\n",
    "df_train = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_0.15\\\\test_somthing\\\\null_data_chars_embedded.csv')\n",
    "df_test = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\characters_articles\\\\edit_ratio_0.15\\\\test_somthing\\\\test_data_chars_embedded.csv')\n",
    "\n",
    "df_train = df_train.sample(frac=1, random_state=RANDOM_STATE)\n",
    "df_test = df_test.sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "X_train = df_train[dim_coulmns]\n",
    "X_test  = df_test[dim_coulmns]\n",
    "X_val = X_test[int(len(X_test) // 2):]\n",
    "X_test = X_test[:int(len(X_test) // 2)]\n",
    "\n",
    "y_train = df_train['has_edits']\n",
    "y_test  = df_test['has_edits']\n",
    "y_val = y_test[int(len(y_test) // 2):]\n",
    "y_test = y_test[:int(len(y_test) // 2)]\n",
    "\n",
    "# Set the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Train SVM model\n",
    "clf = SVC(random_state=RANDOM_STATE)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train the final model on the combined train and validation sets\n",
    "final_model = SVC(C=grid_search.best_params_['C'], gamma=grid_search.best_params_['gamma'], kernel=grid_search.best_params_['kernel']\n",
    "                  , probability=True, random_state=RANDOM_STATE)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = final_model.predict_proba(X_val)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "best_threshold, auc_roc = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "best_threshold_at_fpr_005, _ = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "\n",
    "# Evaluate the final model on the test set\n",
    "y_pred = final_model.predict_proba(X_test)\n",
    "y_pred = y_pred[:, 1]\n",
    "\n",
    "y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_threshold).ravel()\n",
    "FPR = fp / (fp + tn)\n",
    "\n",
    "print(f'AUC {auc_roc}')\n",
    "print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)} FPR@{FPR}')\n",
    "print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold_fpr_005)} FPR@0.05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4b542c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractDataset\n",
      "Test accuracy 0.6135458167330677\n",
      "Test accuracy FPR@0.05 0.5936254980079682\n"
     ]
    }
   ],
   "source": [
    "# Run SVM on specifi data SecondDataset asd\n",
    "number_of_sentences = 50\n",
    "edit_ratio = 10\n",
    "\n",
    "topics = ['AbstractDataset']#, 'NewsDataset', 'WikiDataset']\n",
    "auc_avg = 0\n",
    "thrshld = 0\n",
    "thrshld_005 = 0\n",
    "models = []\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{number_of_sentences}_sentences\\\\{edit_ratio}'\n",
    "    \n",
    "#     # Read data\n",
    "#     df_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_edited.csv')\n",
    "#     df_not_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_not_edited.csv')\n",
    "#     df_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_edited.csv')\n",
    "#     df_not_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_not_edited.csv')\n",
    "    \n",
    "#     # Add label\n",
    "#     df_edited_train['has_edits'] = 1\n",
    "#     df_not_edited_train['has_edits'] = 0\n",
    "#     df_edited_test['has_edits'] = 1\n",
    "#     df_not_edited_test['has_edits'] = 0\n",
    "    \n",
    "#     #Combine the data\n",
    "#     df_train = pd.concat([df_edited_train, df_not_edited_train], ignore_index=True)\n",
    "#     df_train = df_train.sample(frac=1)\n",
    "    \n",
    "    df_train = pd.read_csv(f'{files_path}\\\\model_name_combined_train.csv')\n",
    "    df_validation = pd.read_csv(f'{files_path}\\\\model_name_combined_validation.csv')\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\model_name_combined_test.csv')\n",
    "    \n",
    "    df_train = df_train[df_train['topic']==topic]\n",
    "    df_validation = df_validation[df_validation['topic']==topic]\n",
    "    df_test = df_test[df_test['topic']==topic]\n",
    "    \n",
    "    df_train = df_train.sample(frac=1)[:700]\n",
    "    df_validation = df_validation.sample(frac=1)[:700]\n",
    "    df_test = df_test.sample(frac=1)[:700]\n",
    "    \n",
    "    dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "    X_train = df_train[dim_coulmns] #df_train.drop(columns=['Unnamed: 0', 'has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "    X_val   = df_validation[dim_coulmns] #df_validation.drop(columns=['Unnamed: 0', 'has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "    X_test  = df_test[dim_coulmns] #df_test.drop(columns=['Unnamed: 0','has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "\n",
    "    y_train = df_train['has_edits']\n",
    "    y_val   = df_validation['has_edits']\n",
    "    y_test  = df_test['has_edits']\n",
    "\n",
    "    # Train the final model on the combined train and validation sets\n",
    "    final_model = SVC(C=100, gamma=1, kernel='rbf', probability=True, random_state=555)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    models.append(final_model)\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "214283b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war_articles\n",
      "Test accuracy 0.5235294117647059\n",
      "Test accuracy FPR@0.05 0.5235294117647059\n"
     ]
    }
   ],
   "source": [
    "# Run SVM on specific data mainDataset\n",
    "number_of_sentences = 200\n",
    "edit_ratio = 0.1\n",
    "RANDOM_STATE=555\n",
    "\n",
    "topics = ['war_articles']\n",
    "auc_avg = 0\n",
    "thrshld = 0\n",
    "thrshld_005 = 0\n",
    "models = []\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "    \n",
    "    # Read data\n",
    "    df_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_edited.csv')\n",
    "    df_not_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_not_edited.csv')\n",
    "    df_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_edited.csv')\n",
    "    df_not_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_not_edited.csv')\n",
    "    \n",
    "    # Add label\n",
    "    df_edited_train['has_edits'] = 1\n",
    "    df_not_edited_train['has_edits'] = 0\n",
    "    df_edited_test['has_edits'] = 1\n",
    "    df_not_edited_test['has_edits'] = 0\n",
    "    \n",
    "    #Combine the data\n",
    "    df_train = pd.concat([df_edited_train, df_not_edited_train], ignore_index=True).sample(frac=1, random_state=RANDOM_STATE)\n",
    "    df_val = df_train[int(len(df_train) * 0.8):]\n",
    "    df_train = df_train[:int(len(df_train) * 0.8)]\n",
    "    df_test = pd.concat([df_edited_test, df_not_edited_test], ignore_index=True).sample(frac=1)\n",
    "    \n",
    "    dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "    X_train = df_train[dim_coulmns]\n",
    "    X_val   = df_val[dim_coulmns]\n",
    "    X_test  = df_test[dim_coulmns]\n",
    "\n",
    "    y_train = df_train['has_edits']\n",
    "    y_val   = df_val['has_edits']\n",
    "    y_test  = df_test['has_edits']\n",
    "\n",
    "    # Train the final model on the combined train and validation sets\n",
    "    final_model = SVC(C=100, gamma='scale', kernel='linear', probability=True, random_state=RANDOM_STATE)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    models.append(final_model)\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred <= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred <= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87b967",
   "metadata": {},
   "source": [
    "### **Cross Validation main dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ad0dd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.86it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.52it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 29.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 29.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.80it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 27.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 26.78it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 32.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# corss validation Maindataset\n",
    "edit_ratios = [0.05, 0.1, 0.15] \n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles'] \n",
    "k_folds = 10\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "SEED = 555\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "#         print(f'topic: {topic} edit_ratio: {edit_ratio}')\n",
    "        \n",
    "        # Get data\n",
    "        files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "        file_edited_path = f'{files_path}\\\\{topic}_embedded_edited.csv'\n",
    "        file_not_edited_path = f'{files_path}\\\\{topic}_embedded_not_edited.csv'\n",
    "        \n",
    "        df_edited = pd.read_csv(file_edited_path)\n",
    "        df_not_edited = pd.read_csv(file_not_edited_path)\n",
    "        \n",
    "        # Add label\n",
    "        df_edited['edited'] = 1\n",
    "        df_not_edited['edited'] = 0\n",
    "        \n",
    "        dim_columns = [column for column in df_edited.columns if 'dim_' in column]\n",
    "        results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold', 'C', 'gamma', 'kernel', 'accuracy', 'accuracy_at_FPR_005'])\n",
    "        \n",
    "        # Get splits\n",
    "        splits = [i for i in range(0, len(df_edited), len(df_edited) // k_folds)]\n",
    "\n",
    "        # Do it k_folds times\n",
    "        for fold in tqdm(range(k_folds)):\n",
    "\n",
    "            # Create the split\n",
    "            df_null = None\n",
    "            df_test = None\n",
    "            window_size = 1 # Determine the window size, make it easy to adjust the train/test ratio. Example 1 => 90-10 when k_folds=10\n",
    "\n",
    "            for i in range(len(splits) - 1):\n",
    "                temp_df = pd.concat([df_edited.iloc[splits[i]:splits[i+1]], df_not_edited.iloc[splits[i]:splits[i+1]]], ignore_index=True)\n",
    "                if i == fold: # Take test\n",
    "                    if df_test is None:\n",
    "                        df_test = temp_df\n",
    "                    else:\n",
    "                        df_test = pd.concat([df_test, temp_df])\n",
    "                else: # Take null\n",
    "                    if window_size > 1:\n",
    "                        if df_test is None:\n",
    "                            df_test = temp_df\n",
    "                        else:\n",
    "                            df_test = pd.concat([df_test, temp_df])\n",
    "                        window_size -= 1\n",
    "                        continue\n",
    "\n",
    "                    if df_null is None:\n",
    "                        df_null = temp_df\n",
    "                    else:\n",
    "                        df_null = pd.concat([df_null, temp_df])\n",
    "               \n",
    "            if df_test is None:\n",
    "                continue\n",
    "\n",
    "            df_null = df_null.sample(frac=1, random_state=SEED)\n",
    "            df_test = df_test.sample(frac=1, random_state=SEED)\n",
    "\n",
    "            df_val = df_null[int(len(df_null) * 0.2):]                \n",
    "            df_null = df_null[:int(len(df_null) * 0.2)]\n",
    "            \n",
    "            best_parameters = {\n",
    "                'topic': [topic], \n",
    "                'model': ['embedding'],\n",
    "                'edit_ratio': [edit_ratio],\n",
    "                'fold': [fold],\n",
    "                'C': [0],\n",
    "                'gamma': [0],\n",
    "                'kernel': [''],\n",
    "                'accuracy': [0]\n",
    "            }\n",
    "                  \n",
    "            if df_test is None:\n",
    "                continue\n",
    "                \n",
    "            # Do a grid search\n",
    "#             for c in param_grid['C']:\n",
    "#                 for gamma in param_grid['gamma']:\n",
    "#                     for kernel in param_grid['kernel']:\n",
    "            ###\n",
    "            # Train the model on the train set\n",
    "            model = LogisticRegression(random_state=SEED)\n",
    "#             model = SVC(C=c, gamma=gamma, kernel=kernel, probability=True, random_state=SEED)\n",
    "            model.fit(df_null[dim_columns], df_null['edited'].values)\n",
    "\n",
    "            pred = model.predict_proba(df_val[dim_columns])[:, 1]\n",
    "\n",
    "            # Compute the ROC curve\n",
    "            fpr, tpr, thresholds = roc_curve(df_val['edited'].values, pred)\n",
    "\n",
    "            # Find the threshold that corresponds to the desired FPR (0.05)\n",
    "            desired_fpr = 0.05\n",
    "            threshold = thresholds[np.where(fpr <= desired_fpr)[0][-1]]\n",
    "\n",
    "            pred = model.predict_proba(df_test[dim_columns])[:, 1]\n",
    "\n",
    "            # Apply the threshold to get final predictions\n",
    "            pred_adjusted = (pred >= threshold).astype(int)\n",
    "\n",
    "            acc_at_fpr_005 = accuracy_score(df_test['edited'].values, pred_adjusted)\n",
    "\n",
    "            pred = model.predict(df_test[dim_columns])\n",
    "            acc = accuracy_score(df_test['edited'].values, pred)\n",
    "\n",
    "            fpr = calculate_fpr(df_test['edited'].values, pred)\n",
    "\n",
    "            if acc > best_parameters['accuracy'][0]:\n",
    "                best_parameters['C'] = [c]\n",
    "                best_parameters['gamma'] = [gamma]\n",
    "                best_parameters['kernel'] = [kernel]\n",
    "                best_parameters['accuracy'] = [acc]\n",
    "                best_parameters['FPR'] = [fpr]\n",
    "                best_parameters['accuracy_at_FPR_005'] = [acc_at_fpr_005]\n",
    "            ###\n",
    "            \n",
    "            # Save reults for the current fold\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(best_parameters)])\n",
    "\n",
    "        results_df.reset_index(drop=True)\n",
    "        results_df.to_csv(f'{files_path}\\\\folds_results_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5cdb9815",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Append results to the results file\n",
    "# results_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset_results_.csv'\n",
    "# df_results = pd.read_csv(results_path)\n",
    "\n",
    "edit_ratios = [0.05, 0.1, 0.15] \n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles'] \n",
    "lst_df = []\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        df = pd.read_csv(f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\folds_results_embedding.csv')\n",
    "        results_obj = {\n",
    "            'topic': [topic],\n",
    "            'model': ['embedding'],\n",
    "            'edit_ratio': [edit_ratio],\n",
    "            'accuracy': [df['accuracy'].mean()],\n",
    "            'FPR': [df['FPR'].mean()],\n",
    "            'accuracy_std': [df['accuracy'].std()], \n",
    "            'accuracy_005': [df['accuracy_at_FPR_005'].mean()],\n",
    "            'accuracy_005_std': [df['accuracy_at_FPR_005'].std()]\n",
    "        }\n",
    "        lst_df.append(pd.DataFrame(results_obj))\n",
    "#         df_results = pd.concat([df_results, pd.DataFrame(results_obj)], ignore_index=True)\n",
    "\n",
    "df_results = pd.concat(lst_df, ignore_index=True)\n",
    "df_results.to_csv('SVM_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3d808cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': ['combine'], 'model': ['embedding'], 'edit_ratio': [0.05], 'accuracy': [0.5222222222222221], 'FPR': [0.8222222222222222], 'accuracy_std': [0.05037581669902016], 'accuracy_005': [0.4916666666666667], 'accuracy_005_std': [0.03220838357578906]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': ['combine'], 'model': ['embedding'], 'edit_ratio': [0.1], 'accuracy': [0.5123456790123456], 'FPR': [0.6666666666666665], 'accuracy_std': [0.1021670207903422], 'accuracy_005': [0.5030864197530864], 'accuracy_005_std': [0.025776686864953817]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:08<00:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': ['combine'], 'model': ['embedding'], 'edit_ratio': [0.15], 'accuracy': [0.511764705882353], 'FPR': [0.3941176470588236], 'accuracy_std': [0.09112901991076276], 'accuracy_005': [0.49411764705882355], 'accuracy_005_std': [0.02702754657272593]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# corss validation Maindataset combine topics\n",
    "edit_ratios = [0.05, 0.1, 0.15] \n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles'] \n",
    "k_folds = 10\n",
    "SEED = 555\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "\n",
    "for edit_ratio in edit_ratios:\n",
    "    \n",
    "    # Combine topics\n",
    "    lst_edited = []\n",
    "    lst_not_edited = []\n",
    "    for topic in topics:\n",
    "        files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "        file_edited_path = f'{files_path}\\\\{topic}_embedded_edited.csv'\n",
    "        file_not_edited_path = f'{files_path}\\\\{topic}_embedded_not_edited.csv'\n",
    "        \n",
    "        df_edited = pd.read_csv(file_edited_path)\n",
    "        df_not_edited = pd.read_csv(file_not_edited_path)\n",
    "        \n",
    "        # Add label\n",
    "        df_edited['edited'] = 1\n",
    "        df_not_edited['edited'] = 0\n",
    "        \n",
    "        lst_edited.append(df_edited)\n",
    "        lst_not_edited.append(df_not_edited)\n",
    "        \n",
    "    df_edited = pd.concat(lst_edited, ignore_index=True)\n",
    "    df_not_edited = pd.concat(lst_not_edited, ignore_index=True)\n",
    "    \n",
    "    df_edited = df_edited.sample(frac=1, random_state=SEED)[:int(len(df_edited)*0.2)]\n",
    "    df_not_edited = df_not_edited.sample(frac=1, random_state=SEED)[:int(len(df_not_edited)*0.2)]\n",
    "        \n",
    "    dim_columns = [column for column in df_edited.columns if 'dim_' in column]\n",
    "    results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold', 'accuracy', 'accuracy_at_FPR_005'])\n",
    "\n",
    "    # Get splits\n",
    "    splits = [i for i in range(0, len(df_edited), len(df_edited) // k_folds)]\n",
    "\n",
    "    # Do it k_folds times\n",
    "    for fold in tqdm(range(k_folds)):\n",
    "\n",
    "        # Create the split\n",
    "        df_null = None\n",
    "        df_test = None\n",
    "        window_size = 1 # Determine the window size, make it easy to adjust the train/test ratio. Example 1 => 90-10\n",
    "\n",
    "        for i in range(len(splits) - 1):\n",
    "            temp_df = pd.concat([df_edited.iloc[splits[i]:splits[i+1]], df_not_edited.iloc[splits[i]:splits[i+1]]], ignore_index=True)\n",
    "            if i == fold: # Take test\n",
    "                if df_test is None:\n",
    "                    df_test = temp_df\n",
    "                else:\n",
    "                    df_test = pd.concat([df_test, temp_df])\n",
    "            else: # Take null\n",
    "                if window_size > 1:\n",
    "                    if df_test is None:\n",
    "                        df_test = temp_df\n",
    "                    else:\n",
    "                        df_test = pd.concat([df_test, temp_df])\n",
    "                    window_size -= 1\n",
    "                    continue\n",
    "\n",
    "                if df_null is None:\n",
    "                    df_null = temp_df\n",
    "                else:\n",
    "                    df_null = pd.concat([df_null, temp_df])\n",
    "                    \n",
    "        if df_test is None:\n",
    "            continue\n",
    "\n",
    "        df_null = df_null.sample(frac=1, random_state=SEED)\n",
    "        df_test = df_test.sample(frac=1, random_state=SEED)\n",
    "        \n",
    "        df_val = df_null[int(len(df_null) * 0.2):]                \n",
    "        df_null = df_null[:int(len(df_null) * 0.2)]\n",
    "\n",
    "        best_parameters = {\n",
    "            'topic': ['combine'], \n",
    "            'model': ['embedding'],\n",
    "            'edit_ratio': [edit_ratio],\n",
    "            'fold': [fold],\n",
    "            'accuracy': [0]\n",
    "        }\n",
    "\n",
    "        \n",
    "        # Do a grid search\n",
    "        for c in param_grid['C']:\n",
    "            for gamma in param_grid['gamma']:\n",
    "                for kernel in param_grid['kernel']:\n",
    "                    ###\n",
    "                    # Train the model on the train set\n",
    "                    model = LogisticRegression(random_state=SEED)\n",
    "#                     model = SVC(C=c, gamma=gamma, kernel=kernel, probability=True, random_state=SEED)\n",
    "                    model.fit(df_null[dim_columns], df_null['edited'].values)\n",
    "\n",
    "                    pred = model.predict_proba(df_val[dim_columns])[:, 1]\n",
    "\n",
    "                    # Compute the ROC curve\n",
    "                    fpr, tpr, thresholds = roc_curve(df_val['edited'].values, pred)\n",
    "\n",
    "                    # Find the threshold that corresponds to the desired FPR (0.05)\n",
    "                    desired_fpr = 0.05\n",
    "                    threshold = thresholds[np.where(fpr <= desired_fpr)[0][-1]]\n",
    "\n",
    "                    pred = model.predict_proba(df_test[dim_columns])[:, 1]\n",
    "\n",
    "                    # Apply the threshold to get final predictions\n",
    "                    pred_adjusted = (pred >= threshold).astype(int)\n",
    "\n",
    "                    acc_at_fpr_005 = accuracy_score(df_test['edited'].values, pred_adjusted)\n",
    "\n",
    "                    pred = model.predict(df_test[dim_columns])\n",
    "                    acc = accuracy_score(df_test['edited'].values, pred)\n",
    "\n",
    "                    fpr = calculate_fpr(df_test['edited'].values, pred)\n",
    "\n",
    "                    if acc > best_parameters['accuracy'][0]:\n",
    "                        best_parameters['accuracy'] = [acc]\n",
    "                        best_parameters['FPR'] = [fpr]\n",
    "                        best_parameters['accuracy_at_FPR_005'] = [acc_at_fpr_005]\n",
    "                    ###\n",
    "        # Save reults for the current fold\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(best_parameters)])\n",
    "\n",
    "    print({\n",
    "        'topic': ['combine'],\n",
    "        'model': ['embedding'],\n",
    "        'edit_ratio': [edit_ratio],\n",
    "        'accuracy': [results_df['accuracy'].mean()],\n",
    "        'FPR': [results_df['FPR'].mean()],\n",
    "        'accuracy_std': [results_df['accuracy'].std()], \n",
    "        'accuracy_005': [results_df['accuracy_at_FPR_005'].mean()],\n",
    "        'accuracy_005_std': [results_df['accuracy_at_FPR_005'].std()]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e9f6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiDataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run Cross validation on specifi data SecondDataset\n",
    "number_of_sentences = 200\n",
    "edit_ratio = 10\n",
    "k_folds = 10\n",
    "topics = ['WikiDataset']#'AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold', 'C', 'gamma', 'kernel', 'accuracy', 'accuracy_at_FPR_005'])\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    # Get data\n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{number_of_sentences}_sentences\\\\{edit_ratio}'\n",
    "    df_train = pd.read_csv(f'{files_path}\\\\model_name_combined_train.csv')\n",
    "    df_validation = pd.read_csv(f'{files_path}\\\\model_name_combined_validation.csv')\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\model_name_combined_test.csv')\n",
    "    \n",
    "    # Get topics' data\n",
    "    df_train = df_train[df_train['topic']==topic]\n",
    "    df_validation = df_validation[df_validation['topic']==topic]\n",
    "    df_test = df_test[df_test['topic']==topic]\n",
    "    \n",
    "    df_combined = pd.concat([df_train, df_validation, df_test], ignore_index=True).sample(frac=1)\n",
    "    dim_coulmns = [column for column in df_combined.columns if 'dim_' in column]\n",
    "    \n",
    "    # Do cross validation split and test\n",
    "    splits = [i for i in range(0, len(df_combined), len(df_combined) // k_folds)]\n",
    "    \n",
    "    # Do it k_folds times\n",
    "    for fold in tqdm(range(k_folds)):\n",
    "\n",
    "        # Create the split\n",
    "        df_null = None\n",
    "        df_test = None\n",
    "\n",
    "        for i in range(len(splits) - 1):\n",
    "            tem_df = df_combined.iloc[splits[i]:splits[i+1]]\n",
    "            if i == fold: # Take test\n",
    "                df_test = tem_df\n",
    "            else: # Take null\n",
    "                if df_null is None:\n",
    "                    df_null = tem_df\n",
    "                else:\n",
    "                    df_null = pd.concat([df_null, tem_df])\n",
    "\n",
    "        df_val = df_null[int(len(df_null) * 0.8):]\n",
    "        df_null = df_null[:int(len(df_null) * 0.8)]\n",
    "\n",
    "        best_parameters = {\n",
    "            'topic': [topic], \n",
    "            'model': ['embedding'],\n",
    "            'edit_ratio': [edit_ratio],\n",
    "            'fold': [fold],\n",
    "            'C': [0],\n",
    "            'gamma': [0],\n",
    "            'kernel': [''],\n",
    "            'accuracy': [0]\n",
    "        }\n",
    "\n",
    "        if df_test is None:\n",
    "            continue\n",
    "\n",
    "        # Do a grid search\n",
    "        for c in param_grid['C']:\n",
    "            for gamma in param_grid['gamma']:\n",
    "                for kernel in param_grid['kernel']:\n",
    "\n",
    "                    # Train the model on the train set\n",
    "                    model = SVC(C=c, gamma=gamma, kernel=kernel, probability=True, random_state=SEED)\n",
    "                    model.fit(df_null[dim_columns], df_null['has_edits'])\n",
    "\n",
    "                    # Evaluate the final model on the validation set\n",
    "                    y_pred = model.predict_proba(df_val[dim_columns])[:, 1]\n",
    "                    \n",
    "                    auc_roc, best_threshold = check_AUC_ROC(df_val['has_edits'], y_pred, threshold_FPR_at=None)\n",
    "                    _, best_threshold_at_fpr_005 = check_AUC_ROC(df_val['has_edits'], y_pred, threshold_FPR_at=0.05)\n",
    "                    \n",
    "                    # Evaluate the final model on the test set\n",
    "                    y_pred = model.predict_proba(df_test[dim_columns])[:, 1]\n",
    "\n",
    "                    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "                    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "                    \n",
    "                    acc = accuracy_score(df_test['has_edits'], y_pred_threshold)\n",
    "                    acc_at_fpr_005 = accuracy_score(df_test['has_edits'], y_pred_threshold_fpr_005)\n",
    "\n",
    "                    if acc > best_parameters['accuracy'][0]:\n",
    "                        best_parameters['C'] = [c]\n",
    "                        best_parameters['gamma'] = [gamma]\n",
    "                        best_parameters['kernel'] = [kernel]\n",
    "                        best_parameters['accuracy'] = [acc]\n",
    "                        best_parameters['accuracy_at_FPR_005'] = [acc_at_fpr_005]\n",
    "\n",
    "        # Save reults for the current fold\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(best_parameters)])\n",
    "\n",
    "    results_df.reset_index(drop=True)\n",
    "    results_df.to_csv(f'{files_path}\\\\folds_results_embedding.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
