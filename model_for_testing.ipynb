{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0c7130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95049aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_AUC_ROC(df, show_plot=True):\n",
    "    HC_edits = df[df['edited'] == 1]['prediction'].values\n",
    "    HC_original = df[df['edited'] == 0]['prediction'].values\n",
    "    \n",
    "    y_test = [1 for _ in range(len(HC_edits))] + [0 for _ in range(len(HC_original))]\n",
    "    y_prob = list(HC_edits) + list(HC_original)\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    \n",
    "    # Find the index of the point on the ROC curve closest to (0, 1)\n",
    "    best_threshold_index = np.argmax(tpr - fpr)\n",
    "\n",
    "    # Get the threshold corresponding to the point on the ROC curve\n",
    "    best_threshold = thresholds[best_threshold_index]\n",
    "    \n",
    "    if show_plot:\n",
    "        # Calculate the AUC-ROC score\n",
    "        auc_roc = auc(fpr, tpr)\n",
    "\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_roc:.2f} Threshold = {best_threshold:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    return best_threshold\n",
    "\n",
    "def check_results(df):\n",
    "    if 'edited' not in df.columns:\n",
    "        raise RuntimeError('Column \"edited\" is missing')\n",
    "        \n",
    "    if 'prediction' not in df.columns:\n",
    "        raise RuntimeError('Column \"prediction\" is missing')\n",
    "        \n",
    "    y_true = df['edited'].values.astype('int')\n",
    "    y_pred = df['prediction'].values.astype('int')\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    fp = conf_matrix[0, 1]\n",
    "    tn = conf_matrix[0, 0]\n",
    "    fn = conf_matrix[1, 0]\n",
    "    tp = conf_matrix[1, 1]\n",
    "    fpr = fp / (fp + tn)\n",
    "    fnr = fn / (fn + tp)\n",
    "\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"FPR:\", fpr)\n",
    "    print(\"FNR:\", fnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64414f26",
   "metadata": {},
   "source": [
    "#### **SVM(word counts + tfidf)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "ececac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read article from the json string\n",
    "def get_text_article(article_str, get_edits=False, edit_ratio=None):\n",
    "    text = ''\n",
    "    number_of_sentences = article_str.count('sentence\":')\n",
    "    article_obj = eval(article_str)\n",
    "    if edit_ratio is not None:\n",
    "        num_of_edits = number_of_sentences * edit_ratio // 1\n",
    "    else:\n",
    "        num_of_edits = str(article_obj).count('alternative\":')\n",
    "                \n",
    "    for sub_title in article_obj['sub_titles']:\n",
    "        for sentence in sub_title['sentences']:\n",
    "            text += f\"{sentence['sentence']}\\n\"\n",
    "            if get_edits and num_of_edits > 0 and 'alternative' in sentence:\n",
    "                text += f\"{sentence['alternative']}\\n\"\n",
    "                num_of_edits -= 1\n",
    "    return text\n",
    "\n",
    "def get_articles_text_lst(df):\n",
    "    article_text_lst = []\n",
    "    article_label_lst = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        article_obj = eval(df.iloc[i]['article_json'])\n",
    "        for edited in [False, True]:\n",
    "            article_text_lst.append(get_text_article(article_obj, edited))\n",
    "            article_label_lst.append(int(edited))\n",
    "    \n",
    "    return article_text_lst, article_label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ed7d9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "locations_articles\n",
      "Train accuracy 0.5\n",
      "Test accuracy 0.5\n",
      "Test accuracy FPR@0.05 0.5\n"
     ]
    }
   ],
   "source": [
    "#train SVM on combined dataset\n",
    "number_of_sentences =200\n",
    "edit_ratio = 0.1\n",
    "\n",
    "topics = ['locations_articles']#'AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}'\n",
    "    \n",
    "    df_train = pd.read_csv(f'{files_path}\\\\{topic}_null.csv').sample(frac=1)\n",
    "    df_validation = df_train[int(len(df_train) * 0.8 // 1):]\n",
    "    df_train = df_train[:int(len(df_train) * 0.8 // 1)]\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\{topic}_test.csv')\n",
    "    \n",
    "    X_train, y_train = get_articles_text_lst(df_train)\n",
    "    X_val  , y_val = get_articles_text_lst(df_validation)\n",
    "    X_test , y_test = get_articles_text_lst(df_test)\n",
    "    \n",
    "    best_model = SVC(C=0.1, gamma=1, kernel='poly', probability=True, random_state=666)\n",
    "    pipe = Pipeline([('count', CountVectorizer(stop_words='english', max_df=0.75, min_df=5, max_features=10000, ngram_range=(1, 2))),\n",
    "                     ('tfid', TfidfTransformer())]).fit(X_train)\n",
    "\n",
    "    X_train = pipe.transform(X_train).toarray()\n",
    "    X_train = StandardScaler().fit_transform(X_train)\n",
    "    y_train = y_train\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    pred = best_model.predict(X_train)\n",
    "    print(f'Train accuracy {accuracy_score(y_train, pred)}')\n",
    "    \n",
    "    # Get best threshold for the validation set\n",
    "    X_val = pipe.transform(X_val).toarray()\n",
    "    X_val = StandardScaler().fit_transform(X_val)\n",
    "    y_pred = best_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    X_test = pipe.transform(X_test).toarray()\n",
    "    X_test = StandardScaler().fit_transform(X_test)\n",
    "    y_pred = best_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0789aed",
   "metadata": {},
   "source": [
    "#### **embedding-3-small**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a17602b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_l2(x):\n",
    "    x = np.array(x)\n",
    "    if x.ndim == 1:\n",
    "        norm = np.linalg.norm(x)\n",
    "        if norm == 0:\n",
    "            return x\n",
    "        return x / norm\n",
    "    else:\n",
    "        norm = np.linalg.norm(x, 2, axis=1, keepdims=True)\n",
    "        return np.where(norm == 0, x, x / norm)\n",
    "    \n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def create_df_embedding(file_path, embedding_size=370, get_edits=False, edit_ratio=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    client = OpenAI(api_key='XXX')\n",
    "    columns = ['article_index'] + [f'dim_{i+1}' for i in range(embedding_size)]\n",
    "    embedding_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        article_str = df.iloc[i]['article_json']\n",
    "        article_text = get_text_article(article_str, get_edits, edit_ratio)\n",
    "\n",
    "        # Max token\n",
    "        if num_tokens_from_string(article_text, \"cl100k_base\") > 8191:\n",
    "            continue\n",
    "\n",
    "        response = client.embeddings.create(model=\"text-embedding-3-small\", input=article_text, encoding_format=\"float\")\n",
    "\n",
    "        cut_dim = response.data[0].embedding[:embedding_size]\n",
    "        norm_dim = normalize_l2(cut_dim)\n",
    "\n",
    "        embedding_df = pd.concat([embedding_df, pd.DataFrame([[i] + list(norm_dim)], columns=columns)])\n",
    "        \n",
    "    return embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "92a89256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: locations_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [00:46<00:00,  1.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [00:59<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: locations_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 81/81 [00:40<00:00,  2.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 107/107 [00:51<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: nature_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [01:09<00:00,  1.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:56<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: nature_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 112/112 [01:10<00:00,  1.60it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 91/91 [00:52<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [01:16<00:00,  1.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:26<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: video_games_series_movies_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 136/136 [01:17<00:00,  1.75it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 47/47 [00:20<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.1 get_edits: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [00:59<00:00,  1.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 93/93 [00:52<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: war_articles edit_ratio: 0.1 get_edits: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 108/108 [01:03<00:00,  1.70it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 93/93 [00:46<00:00,  2.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create embedded data main dataset\n",
    "edit_ratios = [0.1] #0.05, 0.1, \n",
    "topics = ['locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles'] #'characters_articles', \n",
    "has_edits = [False, True]\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        for get_edits in has_edits:\n",
    "            print(f'topic: {topic} edit_ratio: {edit_ratio} get_edits: {get_edits}')\n",
    "            suffix = 'edited' if get_edits else 'not_edited'\n",
    "            file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\{topic}_null.csv'\n",
    "            dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\{topic}_embedded_{suffix}.csv'\n",
    "\n",
    "            embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits, edit_ratio=edit_ratio)\n",
    "            embedding_df.to_csv(dest_path)\n",
    "            \n",
    "            file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\{topic}_test.csv'\n",
    "            dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\{topic}_test_embedded_{suffix}.csv'\n",
    "\n",
    "            embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits, edit_ratio=edit_ratio)\n",
    "            embedding_df.to_csv(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32395c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedded data second dataset\n",
    "edit_ratios = [10] #, 20\n",
    "num_of_sentences = [200] #50, 100, \n",
    "topics = ['AbstractDataset'] #'WikiDataset', 'NewsDataset', \n",
    "has_edits = [False, True]\n",
    "\n",
    "for topic in topics:\n",
    "    for num in num_of_sentences:\n",
    "        for edit_ratio in edit_ratios:\n",
    "            for get_edits in has_edits:\n",
    "                print(f'topic: {topic} edit_ratio: {edit_ratio} get_edits: {get_edits}')\n",
    "                suffix = 'edited' if get_edits else 'not_edited'\n",
    "                \n",
    "                file_name = 'model_name_Research_Abstracts_null';\n",
    "                file_name = 'model_name_news_articles_null' if topic == 'NewsDataset' else file_name\n",
    "                file_name = 'model_name_wiki_intro_null' if topic == 'WikiDataset' else file_name\n",
    "                \n",
    "                \n",
    "                file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}.csv'\n",
    "                dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}_embedded_{suffix}.csv'\n",
    "\n",
    "                embedding_df = create_df_embedding(file_path, embedding_size=370, get_edits=get_edits)\n",
    "                embedding_df.to_csv(dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61891489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the files\n",
    "edit_ratios = [20] #, 20\n",
    "num_of_sentences = [200] #, 100, 200\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset'] # \n",
    "has_edits = [False, True]\n",
    "df = None\n",
    "for topic in topics:\n",
    "    for num in num_of_sentences:\n",
    "        for edit_ratio in edit_ratios:\n",
    "            for get_edits in has_edits:\n",
    "                suffix = 'edited' if get_edits else 'not_edited'\n",
    "                \n",
    "                file_name = 'model_name_Research_Abstracts_null';\n",
    "                file_name = 'model_name_news_articles_null' if topic == 'NewsDataset' else file_name\n",
    "                file_name = 'model_name_wiki_intro_null' if topic == 'WikiDataset' else file_name\n",
    "                \n",
    "                file_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{num}_sentences\\\\{edit_ratio}\\\\{file_name}_embedded_{suffix}.csv'\n",
    "                if df is None:\n",
    "                    df = pd.read_csv(file_path)\n",
    "                else:\n",
    "                    df = pd.concat([df, pd.read_csv(file_path)])\n",
    "\n",
    "dest_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{num_of_sentences[0]}_sentences\\\\{edit_ratios[0]}'\n",
    "df = df.sample(frac=1)\n",
    "df.to_csv(f'{dest_path}\\\\model_name_combined_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a7c39115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(file_name_train, file_name_test):\n",
    "    df_not_edited = pd.read_csv(f'{file_name_train}_embedded_not_edited.csv')\n",
    "    df_edited = pd.read_csv(f'{file_name_train}_embedded_edited.csv')\n",
    "\n",
    "    df_not_edited.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_edited.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df = pd.concat([df_not_edited, df_edited])\n",
    "    df['y'] = [0 for _ in range(len(df_not_edited))] + [1 for _ in range(len(df_edited))]\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    df_not_edited_test = pd.read_csv(f'{file_name_test}_embedded_not_edited.csv')\n",
    "    df_edited_test = pd.read_csv(f'{file_name_test}_embedded_edited.csv')\n",
    "\n",
    "    df_not_edited_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "    df_edited_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df_test = pd.concat([df_not_edited_test, df_edited_test])\n",
    "    df_test['y'] = [0 for _ in range(len(df_not_edited_test))] + [1 for _ in range(len(df_edited_test))]\n",
    "    df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "38031664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "Best hyperparameters: {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Do a grid search for hyper parameters\n",
    "df_train = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\200_sentences\\\\10\\\\model_name_combined_train.csv')\n",
    "df_validation = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\200_sentences\\\\10\\\\model_name_combined_validation.csv')\n",
    "df_test = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\200_sentences\\\\10\\\\model_name_combined_test.csv')\n",
    "\n",
    "dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "X_train = df_train[dim_coulmns] \n",
    "X_val   = df_validation[dim_coulmns]\n",
    "X_test  = df_test[dim_coulmns]\n",
    "\n",
    "y_train = df_train['has_edits']\n",
    "y_val   = df_validation['has_edits']\n",
    "y_test  = df_test['has_edits']\n",
    "\n",
    "# Set the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Train SVM model\n",
    "clf = SVC(random_state=666)\n",
    "\n",
    "# Use GridSearchCV to find the best hyperparameters\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d6b96c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_AUC_ROC(y_test, y_prob, threshold_FPR_at=None):\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    \n",
    "    if threshold_FPR_at == None:\n",
    "        # Find the index of the point on the ROC curve closest to (0, 1)\n",
    "        best_threshold_index = np.argmax(tpr - fpr)\n",
    "\n",
    "        # Get the threshold corresponding to the point on the ROC curve\n",
    "        best_threshold = thresholds[best_threshold_index]\n",
    "    elif threshold_FPR_at == -1:\n",
    "        # Calculate the sum of TPR and (1 - FPR) for each threshold\n",
    "        optimal_metric = tpr + (1 - fpr)\n",
    "\n",
    "        # Find the index of the maximum value of the optimal metric\n",
    "        optimal_index = optimal_metric.argmax()\n",
    "\n",
    "        # Get the threshold corresponding to the maximum value of the optimal metric\n",
    "        best_threshold = thresholds[optimal_index]\n",
    "    else:\n",
    "        # Find the threshold for FPR = threshold_FPR_at\n",
    "        threshold_index = next(i for i, fpr_value in enumerate(fpr) if fpr_value >= threshold_FPR_at)\n",
    "        best_threshold = thresholds[threshold_index]\n",
    "        \n",
    "    # Calculate the AUC-ROC score\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "\n",
    "    return auc_roc, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4b542c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbstractDataset\n",
      "Test accuracy 0.6135458167330677\n",
      "Test accuracy FPR@0.05 0.5936254980079682\n"
     ]
    }
   ],
   "source": [
    "# Run SVM on specifi data SecondDataset asd\n",
    "number_of_sentences = 50\n",
    "edit_ratio = 10\n",
    "\n",
    "topics = ['AbstractDataset']#, 'NewsDataset', 'WikiDataset']\n",
    "auc_avg = 0\n",
    "thrshld = 0\n",
    "thrshld_005 = 0\n",
    "models = []\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{number_of_sentences}_sentences\\\\{edit_ratio}'\n",
    "    \n",
    "#     # Read data\n",
    "#     df_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_edited.csv')\n",
    "#     df_not_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_not_edited.csv')\n",
    "#     df_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_edited.csv')\n",
    "#     df_not_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_not_edited.csv')\n",
    "    \n",
    "#     # Add label\n",
    "#     df_edited_train['has_edits'] = 1\n",
    "#     df_not_edited_train['has_edits'] = 0\n",
    "#     df_edited_test['has_edits'] = 1\n",
    "#     df_not_edited_test['has_edits'] = 0\n",
    "    \n",
    "#     #Combine the data\n",
    "#     df_train = pd.concat([df_edited_train, df_not_edited_train], ignore_index=True)\n",
    "#     df_train = df_train.sample(frac=1)\n",
    "    \n",
    "    df_train = pd.read_csv(f'{files_path}\\\\model_name_combined_train.csv')\n",
    "    df_validation = pd.read_csv(f'{files_path}\\\\model_name_combined_validation.csv')\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\model_name_combined_test.csv')\n",
    "    \n",
    "    df_train = df_train[df_train['topic']==topic]\n",
    "    df_validation = df_validation[df_validation['topic']==topic]\n",
    "    df_test = df_test[df_test['topic']==topic]\n",
    "    \n",
    "    df_train = df_train.sample(frac=1)[:700]\n",
    "    df_validation = df_validation.sample(frac=1)[:700]\n",
    "    df_test = df_test.sample(frac=1)[:700]\n",
    "    \n",
    "    dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "    X_train = df_train[dim_coulmns] #df_train.drop(columns=['Unnamed: 0', 'has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "    X_val   = df_validation[dim_coulmns] #df_validation.drop(columns=['Unnamed: 0', 'has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "    X_test  = df_test[dim_coulmns] #df_test.drop(columns=['Unnamed: 0','has_edits', 'article_index', 'topic', 'edit_ratio', 'num_of_sentences'])\n",
    "\n",
    "    y_train = df_train['has_edits']\n",
    "    y_val   = df_validation['has_edits']\n",
    "    y_test  = df_test['has_edits']\n",
    "\n",
    "    # Train the final model on the combined train and validation sets\n",
    "    final_model = SVC(C=100, gamma=1, kernel='rbf', probability=True, random_state=666)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    models.append(final_model)\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "214283b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "war_articles\n",
      "Test accuracy 0.5764705882352941\n",
      "Test accuracy FPR@0.05 0.5117647058823529\n"
     ]
    }
   ],
   "source": [
    "# Run SVM on specific data mainDataset\n",
    "number_of_sentences = 200\n",
    "edit_ratio = 0.1\n",
    "\n",
    "topics = ['war_articles']\n",
    "auc_avg = 0\n",
    "thrshld = 0\n",
    "thrshld_005 = 0\n",
    "models = []\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "    \n",
    "    # Read data\n",
    "    df_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_edited.csv')\n",
    "    df_not_edited_train = pd.read_csv(f'{files_path}\\\\{topic}_embedded_not_edited.csv')\n",
    "    df_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_edited.csv')\n",
    "    df_not_edited_test = pd.read_csv(f'{files_path}\\\\{topic}_test_embedded_not_edited.csv')\n",
    "    \n",
    "    # Add label\n",
    "    df_edited_train['has_edits'] = 1\n",
    "    df_not_edited_train['has_edits'] = 0\n",
    "    df_edited_test['has_edits'] = 1\n",
    "    df_not_edited_test['has_edits'] = 0\n",
    "    \n",
    "    #Combine the data\n",
    "    df_train = pd.concat([df_edited_train, df_not_edited_train], ignore_index=True).sample(frac=1)\n",
    "    df_val = df_train[int(len(df_train) * 0.8):]\n",
    "    df_train = df_train[:int(len(df_train) * 0.8)]\n",
    "    df_test = pd.concat([df_edited_test, df_not_edited_test], ignore_index=True).sample(frac=1)\n",
    "    \n",
    "    dim_coulmns = [column for column in df_train.columns if 'dim_' in column]\n",
    "\n",
    "    X_train = df_train[dim_coulmns]\n",
    "    X_val   = df_val[dim_coulmns]\n",
    "    X_test  = df_test[dim_coulmns]\n",
    "\n",
    "    y_train = df_train['has_edits']\n",
    "    y_val   = df_val['has_edits']\n",
    "    y_test  = df_test['has_edits']\n",
    "\n",
    "    # Train the final model on the combined train and validation sets\n",
    "    final_model = SVC(C=100, gamma='scale', kernel='linear', probability=True, random_state=666)\n",
    "    final_model.fit(X_train, y_train)\n",
    "    models.append(final_model)\n",
    "\n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_val)\n",
    "    y_pred = y_pred[:, 1]\n",
    "\n",
    "    auc_roc, best_threshold = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=None)\n",
    "    _, best_threshold_at_fpr_005 = check_AUC_ROC(y_val, y_pred, threshold_FPR_at=0.05)\n",
    "    \n",
    "    # Evaluate the final model on the test set\n",
    "    y_pred = final_model.predict_proba(X_test)\n",
    "    y_pred = y_pred[:, 1]\n",
    "    \n",
    "    y_pred_threshold = list((y_pred <= best_threshold).astype(int))\n",
    "    y_pred_threshold_fpr_005 = list((y_pred <= best_threshold_at_fpr_005).astype(int))\n",
    "    \n",
    "    print(f'Test accuracy {accuracy_score(y_test, y_pred_threshold)}')\n",
    "    print(f'Test accuracy FPR@0.05 {accuracy_score(y_test, y_pred_threshold_fpr_005)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87b967",
   "metadata": {},
   "source": [
    "### **Cross Validation main dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad0dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corss validation Maindataset\n",
    "edit_ratios = [0.1]#[0.05, 0.1, 0.15] \n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles'] \n",
    "k_folds = 10\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "SEED = 555\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "#         print(f'topic: {topic} edit_ratio: {edit_ratio}')\n",
    "        \n",
    "        # Get data\n",
    "        files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "        file_edited_path = f'{files_path}\\\\{topic}_embedded_edited.csv'\n",
    "        file_not_edited_path = f'{files_path}\\\\{topic}_embedded_not_edited.csv'\n",
    "        file_edited_path_test = f'{files_path}\\\\{topic}_test_embedded_edited.csv'\n",
    "        file_not_edited_path_test = f'{files_path}\\\\{topic}_test_embedded_not_edited.csv'\n",
    "        \n",
    "        df_edited = pd.read_csv(file_edited_path)\n",
    "        df_not_edited = pd.read_csv(file_not_edited_path)\n",
    "        df_edited_test = pd.read_csv(file_edited_path_test)\n",
    "        df_not_edited_test = pd.read_csv(file_not_edited_path_test)\n",
    "        \n",
    "        # Add label\n",
    "        df_edited['edited'] = 1\n",
    "        df_not_edited['edited'] = 0\n",
    "        df_edited_test['edited'] = 1\n",
    "        df_not_edited_test['edited'] = 0\n",
    "        \n",
    "        dim_columns = [column for column in df_edited.columns if 'dim_' in column]\n",
    "        results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold', 'C', 'gamma', 'kernel', 'accuracy', 'accuracy_at_FPR_005'])\n",
    "        \n",
    "        # Get splits\n",
    "        splits = [i for i in range(0, len(df_edited), len(df_edited) // k_folds)]\n",
    "\n",
    "        # Do it k_folds times\n",
    "        for fold in tqdm(range(k_folds)):\n",
    "\n",
    "            # Create the split\n",
    "            df_null = None\n",
    "            df_test = None\n",
    "\n",
    "            for i in range(len(splits) - 1):\n",
    "                if i == fold: # Take test\n",
    "                    df_test = pd.concat([df_edited.iloc[splits[i]:splits[i+1]], df_not_edited.iloc[splits[i]:splits[i+1]], df_edited_test.iloc[splits[i]:splits[i+1]], df_not_edited_test.iloc[splits[i]:splits[i+1]]], ignore_index=True)\n",
    "                else: # Take null\n",
    "                    if df_null is None:\n",
    "                        df_null = pd.concat([df_edited.iloc[splits[i]:splits[i+1]], df_not_edited.iloc[splits[i]:splits[i+1]], df_edited_test.iloc[splits[i]:splits[i+1]], df_not_edited_test.iloc[splits[i]:splits[i+1]]], ignore_index=True)\n",
    "                    else:\n",
    "                        tem_df = pd.concat([df_edited.iloc[splits[i]:splits[i+1]], df_not_edited.iloc[splits[i]:splits[i+1]], df_edited_test.iloc[splits[i]:splits[i+1]], df_not_edited_test.iloc[splits[i]:splits[i+1]]], ignore_index=True)\n",
    "                        df_null = pd.concat([df_null, tem_df])\n",
    "                        \n",
    "            df_val = df_null[int(len(df_null) * 0.8):]\n",
    "            df_null = df_null[:int(len(df_null) * 0.8)]\n",
    "                        \n",
    "            best_parameters = {\n",
    "                'topic': [topic], \n",
    "                'model': ['embedding'],\n",
    "                'edit_ratio': [edit_ratio],\n",
    "                'fold': [fold],\n",
    "                'C': [0],\n",
    "                'gamma': [0],\n",
    "                'kernel': [''],\n",
    "                'accuracy': [0]\n",
    "            }\n",
    "                  \n",
    "            if df_test is None:\n",
    "                continue\n",
    "                \n",
    "            # Do a grid search\n",
    "            for c in param_grid['C']:\n",
    "                for gamma in param_grid['gamma']:\n",
    "                    for kernel in param_grid['kernel']:\n",
    "                        \n",
    "                        # Train the model on the train set\n",
    "                        model = SVC(C=c, gamma=gamma, kernel=kernel, probability=True, random_state=SEED)\n",
    "                        model.fit(df_null[dim_columns], df_null['edited'].values)\n",
    "                        \n",
    "                        pred = model.predict_proba(df_test[dim_columns])[:, 1]\n",
    "                        \n",
    "                        # Compute the ROC curve\n",
    "                        fpr, tpr, thresholds = roc_curve(df_test['edited'].values, pred)\n",
    "\n",
    "                        # Find the threshold that corresponds to the desired FPR (0.05)\n",
    "                        desired_fpr = 0.05\n",
    "                        threshold = thresholds[np.where(fpr <= desired_fpr)[0][-1]]\n",
    "                        \n",
    "                        # Apply the threshold to get final predictions\n",
    "                        pred_adjusted = (pred >= threshold).astype(int)\n",
    "\n",
    "                        acc_at_fpr_005 = accuracy_score(df_test['edited'].values, pred_adjusted)\n",
    "                        \n",
    "                        pred = model.predict(df_test[dim_columns])\n",
    "                        acc = accuracy_score(df_test['edited'].values, pred)\n",
    "                        \n",
    "                        if acc > best_parameters['accuracy'][0]:\n",
    "                            best_parameters['C'] = [c]\n",
    "                            best_parameters['gamma'] = [gamma]\n",
    "                            best_parameters['kernel'] = [kernel]\n",
    "                            best_parameters['accuracy'] = [acc]\n",
    "                            best_parameters['accuracy_at_FPR_005'] = [acc_at_fpr_005]\n",
    "                            \n",
    "            # Save reults for the current fold\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(best_parameters)])\n",
    "            \n",
    "        results_df.reset_index(drop=True)\n",
    "        results_df.to_csv(f'{files_path}\\\\folds_results_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4e9f6e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WikiDataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Run Cross validation on specifi data SecondDataset\n",
    "number_of_sentences = 200\n",
    "edit_ratio = 10\n",
    "k_folds = 10\n",
    "topics = ['WikiDataset']#'AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold', 'C', 'gamma', 'kernel', 'accuracy', 'accuracy_at_FPR_005'])\n",
    "\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "    \n",
    "    # Get data\n",
    "    files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Combined\\\\{number_of_sentences}_sentences\\\\{edit_ratio}'\n",
    "    df_train = pd.read_csv(f'{files_path}\\\\model_name_combined_train.csv')\n",
    "    df_validation = pd.read_csv(f'{files_path}\\\\model_name_combined_validation.csv')\n",
    "    df_test = pd.read_csv(f'{files_path}\\\\model_name_combined_test.csv')\n",
    "    \n",
    "    # Get topics' data\n",
    "    df_train = df_train[df_train['topic']==topic]\n",
    "    df_validation = df_validation[df_validation['topic']==topic]\n",
    "    df_test = df_test[df_test['topic']==topic]\n",
    "    \n",
    "    df_combined = pd.concat([df_train, df_validation, df_test], ignore_index=True).sample(frac=1)\n",
    "    dim_coulmns = [column for column in df_combined.columns if 'dim_' in column]\n",
    "    \n",
    "    # Do cross validation split and test\n",
    "    splits = [i for i in range(0, len(df_combined), len(df_combined) // k_folds)]\n",
    "    \n",
    "    # Do it k_folds times\n",
    "    for fold in tqdm(range(k_folds)):\n",
    "\n",
    "        # Create the split\n",
    "        df_null = None\n",
    "        df_test = None\n",
    "\n",
    "        for i in range(len(splits) - 1):\n",
    "            tem_df = df_combined.iloc[splits[i]:splits[i+1]]\n",
    "            if i == fold: # Take test\n",
    "                df_test = tem_df\n",
    "            else: # Take null\n",
    "                if df_null is None:\n",
    "                    df_null = tem_df\n",
    "                else:\n",
    "                    df_null = pd.concat([df_null, tem_df])\n",
    "\n",
    "        df_val = df_null[int(len(df_null) * 0.8):]\n",
    "        df_null = df_null[:int(len(df_null) * 0.8)]\n",
    "\n",
    "        best_parameters = {\n",
    "            'topic': [topic], \n",
    "            'model': ['embedding'],\n",
    "            'edit_ratio': [edit_ratio],\n",
    "            'fold': [fold],\n",
    "            'C': [0],\n",
    "            'gamma': [0],\n",
    "            'kernel': [''],\n",
    "            'accuracy': [0]\n",
    "        }\n",
    "\n",
    "        if df_test is None:\n",
    "            continue\n",
    "\n",
    "        # Do a grid search\n",
    "        for c in param_grid['C']:\n",
    "            for gamma in param_grid['gamma']:\n",
    "                for kernel in param_grid['kernel']:\n",
    "\n",
    "                    # Train the model on the train set\n",
    "                    model = SVC(C=c, gamma=gamma, kernel=kernel, probability=True, random_state=SEED)\n",
    "                    model.fit(df_null[dim_columns], df_null['has_edits'])\n",
    "\n",
    "                    # Evaluate the final model on the validation set\n",
    "                    y_pred = model.predict_proba(df_val[dim_columns])[:, 1]\n",
    "                    \n",
    "                    auc_roc, best_threshold = check_AUC_ROC(df_val['has_edits'], y_pred, threshold_FPR_at=None)\n",
    "                    _, best_threshold_at_fpr_005 = check_AUC_ROC(df_val['has_edits'], y_pred, threshold_FPR_at=0.05)\n",
    "                    \n",
    "                    # Evaluate the final model on the test set\n",
    "                    y_pred = model.predict_proba(df_test[dim_columns])[:, 1]\n",
    "\n",
    "                    y_pred_threshold = list((y_pred >= best_threshold).astype(int))\n",
    "                    y_pred_threshold_fpr_005 = list((y_pred >= best_threshold_at_fpr_005).astype(int))\n",
    "                    \n",
    "                    acc = accuracy_score(df_test['has_edits'], y_pred_threshold)\n",
    "                    acc_at_fpr_005 = accuracy_score(df_test['has_edits'], y_pred_threshold_fpr_005)\n",
    "\n",
    "                    if acc > best_parameters['accuracy'][0]:\n",
    "                        best_parameters['C'] = [c]\n",
    "                        best_parameters['gamma'] = [gamma]\n",
    "                        best_parameters['kernel'] = [kernel]\n",
    "                        best_parameters['accuracy'] = [acc]\n",
    "                        best_parameters['accuracy_at_FPR_005'] = [acc_at_fpr_005]\n",
    "\n",
    "        # Save reults for the current fold\n",
    "        results_df = pd.concat([results_df, pd.DataFrame(best_parameters)])\n",
    "\n",
    "    results_df.reset_index(drop=True)\n",
    "    results_df.to_csv(f'{files_path}\\\\folds_results_embedding.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
