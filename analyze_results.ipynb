{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "800de5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7dabee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_AUC_ROC(df, title='', dist_type='HC', show_plot=True, threshold_FPR_at=None):\n",
    "    HC_edits = df[df['edited'] == 1][dist_type].values\n",
    "    HC_original = df[df['edited'] == 0][dist_type].values\n",
    "    \n",
    "    y_test = [1 for _ in range(len(HC_edits))] + [0 for _ in range(len(HC_original))]\n",
    "    y_prob = list(HC_edits) + list(HC_original)\n",
    "\n",
    "    # Calculate the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "    if threshold_FPR_at == None:\n",
    "        # Find the index of the point on the ROC curve closest to (0, 1)\n",
    "        best_threshold_index = np.argmax(tpr - fpr)\n",
    "\n",
    "        # Get the threshold corresponding to the point on the ROC curve\n",
    "        best_threshold = thresholds[best_threshold_index]\n",
    "    elif threshold_FPR_at == -1:\n",
    "        # Initialize variables to store the best threshold and corresponding best accuracy\n",
    "        best_threshold = thresholds[0]\n",
    "        best_accuracy = 0\n",
    "\n",
    "        # Iterate through thresholds to find the best one\n",
    "        for threshold in thresholds:\n",
    "            # Convert probabilities to binary predictions using the current threshold\n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "\n",
    "            # Calculate the accuracy for the current threshold\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "            # Update the best threshold if the current accuracy is better\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_threshold = threshold\n",
    "    else:\n",
    "        # Find the threshold for FPR = threshold_FPR_at\n",
    "        threshold_index = next(i for i, fpr_value in enumerate(fpr) if fpr_value >= threshold_FPR_at)\n",
    "        best_threshold = thresholds[threshold_index]\n",
    "    \n",
    "    # Calculate the AUC-ROC score\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "#     print(f'auc_roc {auc_roc}')\n",
    "    if show_plot:\n",
    "        # Plot the ROC curve\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {auc_roc:.2f} Threshold = {best_threshold:.2f}')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "        plt.title(f'Receiver Operating Characteristic (ROC) Curve on {dist_type} \\n{title}')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    return best_threshold, auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b25311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 131.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 125.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 120.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 118.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 130.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 134.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 139.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 136.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 138.39it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 136.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 120.42it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 118.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 114.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 121.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 116.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 117.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 121.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 118.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 121.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 204/204 [00:01<00:00, 118.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 114.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 118.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 113.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 114.00it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 106.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 113.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 110.36it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 122.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 118.79it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 111.05it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 103.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 96.38it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 91.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 108.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 117.62it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:01<00:00, 110.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 119.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 116.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 121.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 125.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 104.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 101.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 109.18it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 96.08it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 104.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 104.51it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 99.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 100.68it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 100.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 101.63it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 89.59it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 89.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 108.72it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 94.61it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 94.37it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 96.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 97.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 102.45it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 99.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 60/60 [00:00<00:00, 100.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 119.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 116.17it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 118.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 119.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 125.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 112.96it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 120.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 109.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 117.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 109.66it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 118.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 105.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 104.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 276/276 [00:03<00:00, 89.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 276/276 [00:03<00:00, 91.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 105.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 120.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 128.40it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 113.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 276/276 [00:02<00:00, 113.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 115.48it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 117.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 115.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 116.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 112.04it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 97.21it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 108.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 112.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 109.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 105.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 110.19it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 114.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 121.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 110.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 122.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 133.93it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 130.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 128.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 126.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 123.95it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 129.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 121.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 126.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 127.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 120.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 127.38it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 127.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 129.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 129.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 124.50it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 130.68it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 129.33it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 116.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 122.57it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 125.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 120.76it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 124.12it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 120.24it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 129.90it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 164/164 [00:01<00:00, 117.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 128.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 130.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 125.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 141.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 141.85it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 149.64it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 141.25it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 133.65it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 142.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 148.83it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 144.06it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 142.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 135.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 139.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 144.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 150.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 148.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 148.02it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:03<00:00, 149.56it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 588/588 [00:04<00:00, 125.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 144.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 140.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 143.94it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 138.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 143.59it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 144.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 146.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 144.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 144.86it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 143.28it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 139.41it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 139.71it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 142.11it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 137.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 139.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 129.44it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 125.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 136.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 142.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 324/324 [00:02<00:00, 141.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 119.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 131.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 124.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 122.08it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 117.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 118.52it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 124.10it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 123.51it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 126.88it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 115.81it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 116.98it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 120.97it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 106.82it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 126.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 133.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 123.72it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 127.60it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 126.27it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 129.69it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 170/170 [00:01<00:00, 126.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# Calculate min p values second dataset\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "numbers_sentences = [50, 100, 200]\n",
    "edit_ratios = [0.1, 0.2]\n",
    "\n",
    "for topic in topics:\n",
    "    for number_senteces in numbers_sentences:\n",
    "        for edit_ratio in edit_ratios:\n",
    "            for fold in range(10):\n",
    "                # Get data \n",
    "                folder_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Cross_validation\\\\{topic}\\\\{number_senteces}_sentences\\\\{edit_ratio}\\\\fold_{fold}\\\\results\\\\'\n",
    "                files = glob.glob(f'{folder_path}/*_results.csv')\n",
    "                df = None\n",
    "                for file in files:\n",
    "                    if df is None:\n",
    "                        df = pd.read_csv(file)\n",
    "                    else:\n",
    "                        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "                df = df.reset_index()\n",
    "                df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "                # For each article \n",
    "                for i in tqdm(range(len(df))):\n",
    "                    article_id = df.iloc[i]['Unnamed: 0'].split('_')[1]\n",
    "                    article_type = df.iloc[i]['Unnamed: 0'].split('_')[3]\n",
    "\n",
    "                    # Calc minus log min p value\n",
    "                    current_article_df = pd.read_csv(f'{folder_path}article_{article_id}_sentences_{article_type}.csv')\n",
    "                    minus_log_min_p_value = -math.log(current_article_df['pvalue'].min())\n",
    " \n",
    "                    # Save the results\n",
    "                    article_results_path = f'{folder_path}article_{article_id}_{article_type}_results.csv'\n",
    "                    article_results = pd.read_csv(article_results_path)\n",
    "                    article_results.loc[0, 'minus_log_min_p_value'] = minus_log_min_p_value\n",
    "                    article_results.to_csv(article_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb68c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate min p values main dataset\n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles']\n",
    "edit_ratios = [0.05, 0.1, 0.15]\n",
    "models_names = ['gpt2xl', 'phi2']\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        for model_name in models_names:\n",
    "            for fold in range(10):\n",
    "                results_folder = 'results' if model_name == 'gpt2xl' else 'results_phi2'\n",
    "                folder_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\fold_{fold}\\\\{results_folder}\\\\'\n",
    "                files = glob.glob(f'{folder_path}/*_results.csv')\n",
    "                \n",
    "                # Get data\n",
    "                df = None\n",
    "                for file in files:\n",
    "                    if df is None:\n",
    "                        df = pd.read_csv(file)\n",
    "                    else:\n",
    "                        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "                df = df.reset_index()\n",
    "                df.drop(columns=['index'], inplace=True)\n",
    "\n",
    "                # For each article \n",
    "                for i in tqdm(range(len(df))):\n",
    "                    article_id = df.iloc[i]['Unnamed: 0'].split('_')[1]\n",
    "                    article_type = df.iloc[i]['Unnamed: 0'].split('_')[3]\n",
    "\n",
    "                    # Calc minus log min p value\n",
    "                    current_article_df = pd.read_csv(f'{folder_path}article_{article_id}_sentences_{article_type}.csv')\n",
    "                    minus_log_min_p_value = -math.log(current_article_df['pvalue'].min())\n",
    "\n",
    "                    # Save the results\n",
    "                    article_results_path = f'{folder_path}article_{article_id}_{article_type}_results.csv'\n",
    "                    article_results = pd.read_csv(article_results_path)\n",
    "                    article_results.loc[0, 'minus_log_min_p_value'] = minus_log_min_p_value\n",
    "                    article_results.to_csv(article_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a292f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Best Threshold\n",
    "topics = ['AbstractDataset', 'WikiDataset', 'NewsDataset']\n",
    "numbers_sentences = [50, 100, 200] #  \n",
    "edit_ratios = [10, 20]\n",
    "models = ['GPT2XL', 'Phi2']  \n",
    "threshold_FPR_at = -1 # -1 to get the optimal TPR+(1-FPR) #None to get the closest pont to (0, 1) #0.05 \n",
    "\n",
    "results_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\ForAlon\\\\results_SecondDataset.csv'\n",
    "df_results = pd.read_csv(results_path)\n",
    "\n",
    "for model in models:\n",
    "    suffix = '' if model == 'GPT2XL' else '_phi2'\n",
    "    for topic in topics:\n",
    "        for number_senteces in numbers_sentences:\n",
    "            for edit_ratio in edit_ratios:\n",
    "                \n",
    "                # Get data\n",
    "                folder_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{number_senteces}_sentences\\\\{edit_ratio}\\\\results{suffix}\\\\'\n",
    "                files = glob.glob(f'{folder_path}/*_results.csv')\n",
    "                df = None\n",
    "                for file in files:\n",
    "                    if df is None:\n",
    "                        df = pd.read_csv(file)\n",
    "                    else:\n",
    "                        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "                # Add label\n",
    "                df['edited'] = df['Unnamed: 0'].apply(lambda x: 1 if 'edited' in x else 0)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Get threshold for statistics\n",
    "                dist_type = 'HC'\n",
    "                best_Threshold_HC, _ = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=threshold_FPR_at)\n",
    "\n",
    "                dist_type = 'fisher'\n",
    "                best_Threshold_Fisher, _ = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=threshold_FPR_at)\n",
    "\n",
    "                dist_type = 'minus_log_min_p_value'\n",
    "                best_Threshold_Min_P_value, _ = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=threshold_FPR_at)\n",
    "\n",
    "                # Get the correct line and save it\n",
    "                filter_condition = (\n",
    "                    (df_results['topic'] == topic) & \n",
    "                    (df_results['#Sentences'] == number_senteces) & \n",
    "                    (df_results['edit_ratio'] == edit_ratio) & \n",
    "                    (df_results['model'] == model)\n",
    "                )\n",
    "                df_results.loc[filter_condition, 'best_Threshold_best_acc'] = [best_Threshold_HC, best_Threshold_Fisher, best_Threshold_Min_P_value]\n",
    "                \n",
    "df_results.to_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c769d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate TPR\n",
    "results_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\ForAlon\\\\results_SecondDataset.csv'\n",
    "df_results = pd.read_csv(results_path)\n",
    "\n",
    "topics = ['AbstractDataset', 'WikiDataset', 'NewsDataset']\n",
    "numbers_sentences = [50, 100, 200] \n",
    "edit_ratios = [10, 20]\n",
    "models = ['GPT2XL','Phi2'] \n",
    "statistics = ['HC', 'Min_P_value'] #, 'Fisher'\n",
    "\n",
    "for model in models:\n",
    "    suffix = '' if model == 'GPT2XL' else '_phi2'\n",
    "    for topic in topics:\n",
    "        for number_senteces in numbers_sentences:\n",
    "            for edit_ratio in edit_ratios:\n",
    "                for stat in statistics:\n",
    "                    \n",
    "                    # Get data\n",
    "                    folder_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{number_senteces}_sentences\\\\{edit_ratio}\\\\results{suffix}\\\\test'\n",
    "                    files = glob.glob(f'{folder_path}/*_results.csv')\n",
    "                    df = None\n",
    "                    for file in files:\n",
    "                        if df is None:\n",
    "                            df = pd.read_csv(file)\n",
    "                        else:\n",
    "                            df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "                    # Add label\n",
    "                    df['edited'] = df['Unnamed: 0'].apply(lambda x: 1 if 'edited' in x else 0)\n",
    "                    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                    # Get the correct line to get the threshold\n",
    "                    filter_condition = (\n",
    "                        (df_results['topic'] == topic) & \n",
    "                        (df_results['#Sentences'] == number_senteces) & \n",
    "                        (df_results['edit_ratio'] == edit_ratio) & \n",
    "                        (df_results['statistics'] == stat) &\n",
    "                        (df_results['model'] == model)\n",
    "                    )\n",
    "                    \n",
    "                    best_Threshold = df_results.loc[filter_condition, 'best_Threshold_best_acc'].values[0]\n",
    "                    \n",
    "                    # Use the threshold  \n",
    "                    stat_to_check = 'HC'\n",
    "                    stat_to_check = 'fisher' if stat == 'Fisher' else stat_to_check\n",
    "                    stat_to_check = 'minus_log_min_p_value' if stat == 'Min_P_value' else stat_to_check\n",
    "                    \n",
    "                    df['pred'] = (df[stat_to_check] > best_Threshold).astype(int)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    TP = len(df[(df['pred']==1) & (df['edited']==1)])\n",
    "                    FN = len(df[(df['pred']==0) & (df['edited']==1)])\n",
    "                    FP = len(df[(df['pred']==1) & (df['edited']==0)])\n",
    "                    TN = len(df[(df['pred']==0) & (df['edited']==0)])\n",
    "                    \n",
    "                    TPR = TP / (TP + FN)\n",
    "                    FPR = FP / (FP + TN)\n",
    "                    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "                    \n",
    "                    # Save results\n",
    "                    df_results.loc[filter_condition, 'TPR_at_FPR_005_test'] = TPR\n",
    "                    df_results.loc[filter_condition, 'FPR_test'] = FPR\n",
    "                    df_results.loc[filter_condition, 'Accuracy_test_best_acc'] = accuracy\n",
    "                    \n",
    "df_results.to_csv(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d46b001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_roc 0.74065\n",
      "2.4422686826989795\n",
      "TPR 0.295 FPR 0.05\n"
     ]
    }
   ],
   "source": [
    "# Calculate Best Threshold for specific topic second dataset\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "numbers_sentences = [200] # 50, 100, 200\n",
    "edit_ratios = [20] #, 20\n",
    "models = ['Phi2'] # GPT2XL\n",
    "threshold_FPR_at = 0.05#-1 # -1 to get the optimal TPR+(1-FPR) #None #0.05\n",
    "\n",
    "results_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\ForAlon\\\\results_SecondDataset_embedding.csv'\n",
    "df_results = pd.read_csv(results_path)\n",
    "\n",
    "df = None\n",
    "for topic in topics:\n",
    "    HC_results_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\{topic}\\\\{numbers_sentences[0]}_sentences\\\\{edit_ratios[0]}'\n",
    "    results_folder = 'results_phi2' if models[0] == 'Phi2' else 'results'\n",
    "    results_folder = f'{HC_results_path}\\\\{results_folder}'\n",
    "    \n",
    "    # Get data\n",
    "    files = glob.glob(f'{results_folder}/*_results.csv')\n",
    "    for file in files:\n",
    "        if df is None:\n",
    "            df = pd.read_csv(file)\n",
    "        else:\n",
    "            df = pd.concat([df, pd.read_csv(file)])\n",
    "    \n",
    "    # Add label\n",
    "    df['edited'] = df['Unnamed: 0'].apply(lambda x: 1 if 'edited' in x else 0)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# Get threshold\n",
    "dist_type = 'HC'\n",
    "best_Threshold_HC, _ = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=threshold_FPR_at)\n",
    "print(best_Threshold_HC)\n",
    "\n",
    "# Use threshold\n",
    "df['pred'] = df['HC'].apply(lambda x: 1 if x >= best_Threshold_HC else 0)\n",
    "\n",
    "# Calculate metrics\n",
    "TP = len(df[(df['pred']==1) & (df['edited']==1)])\n",
    "FN = len(df[(df['pred']==0) & (df['edited']==1)])\n",
    "FP = len(df[(df['pred']==1) & (df['edited']==0)])\n",
    "TN = len(df[(df['pred']==0) & (df['edited']==0)])\n",
    "\n",
    "TPR = TP / (TP + FN)\n",
    "FPR = FP / (FP + TN)\n",
    "print(f'TPR {TPR} FPR {FPR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c03b7",
   "metadata": {},
   "source": [
    "### **Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee83fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(df, true_label, pred_label):\n",
    "    TP = len(df[(df[pred_label]==1) & (df[true_label]==1)])\n",
    "    FN = len(df[(df[pred_label]==0) & (df[true_label]==1)])\n",
    "    FP = len(df[(df[pred_label]==1) & (df[true_label]==0)])\n",
    "    TN = len(df[(df[pred_label]==0) & (df[true_label]==0)])\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return TPR, FPR, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e147e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create results csv for each fold\n",
    "# Cross validation for mainDataset folds\n",
    "edit_ratios = [0.1] #[0.05, 0.1, 0.15]\n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles']\n",
    "k_folds = 10\n",
    "models_names = ['gpt2xl', 'Phi2']\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "        df = None\n",
    "        results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio', 'fold'\n",
    "                                           , 'best_Threshold_HC', 'AUC_ROC', 'TPR', 'FPR', 'accuracy'\n",
    "                                           , 'best_Threshold_HC_005', 'AUC_ROC_005', 'TPR_005', 'FPR_005', 'accuracy_005'\n",
    "                                           , 'best_Threshold_HC_optimal_acc', 'AUC_ROC_optimal_acc', 'TPR_optimal_acc'\n",
    "                                           , 'FPR_optimal_acc', 'accuracy_optimal_acc'\n",
    "                                           , 'best_Threshold_minp', 'AUC_ROC_minp', 'TPR_minp', 'FPR_minp', 'accuracy_minp'\n",
    "                                           , 'best_Threshold_minp_005', 'AUC_ROC_005_minp', 'TPR_005_minp', 'FPR_005_minp', 'accuracy_005_minp'\n",
    "                                           , 'best_Threshold_minp_optimal_acc', 'AUC_ROC_optimal_acc_minp', 'TPR_optimal_acc_minp'\n",
    "                                           , 'FPR_optimal_acc_minp', 'accuracy_optimal_acc_minp'])\n",
    "\n",
    "        # For each fold\n",
    "        for fold in tqdm(range(k_folds)):\n",
    "            for model_name in models_names:\n",
    "                # Init\n",
    "                results_folder = 'results_phi2' if model_name == 'Phi2' else 'results'\n",
    "                results_folder = f'{files_path}\\\\fold_{fold}\\\\{results_folder}'\n",
    "                results_obj = {\n",
    "                    'topic': [topic],\n",
    "                    'model': [model_name],\n",
    "                    'edit_ratio': [edit_ratio],\n",
    "                    'fold': [fold]\n",
    "                }\n",
    "\n",
    "                # Get results files\n",
    "                files = glob.glob(f'{results_folder}/*_results.csv')\n",
    "                for file in files:\n",
    "                    if df is None:\n",
    "                        df = pd.read_csv(file)\n",
    "                    else:\n",
    "                        df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "                df['edited'] = df['Unnamed: 0'].apply(lambda x: 1 if 'edited' in x else 0)\n",
    "                df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Get thresholds HC\n",
    "                dist_type = 'HC'\n",
    "                best_Threshold_HC, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=None)\n",
    "                results_obj['best_Threshold_HC'] = [best_Threshold_HC]\n",
    "                results_obj['AUC_ROC'] = [auc_roc]\n",
    "\n",
    "                best_Threshold_HC_005, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=0.05)\n",
    "                results_obj['best_Threshold_HC_005'] = [best_Threshold_HC_005]\n",
    "                results_obj['AUC_ROC_005'] = [auc_roc]\n",
    "\n",
    "                best_Threshold_HC_optimal_acc, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=-1)\n",
    "                results_obj['best_Threshold_HC_optimal_acc'] = [best_Threshold_HC_optimal_acc]\n",
    "                results_obj['AUC_ROC_optimal_acc'] = [auc_roc]\n",
    "\n",
    "                # Use threshold\n",
    "                df['pred'] = df['HC'].apply(lambda x: 1 if x >= best_Threshold_HC else 0)\n",
    "                df['pred_FPR_005'] = df['HC'].apply(lambda x: 1 if x >= best_Threshold_HC_005 else 0)\n",
    "                df['pred_optimal_acc'] = df['HC'].apply(lambda x: 1 if x >= best_Threshold_HC_optimal_acc else 0)\n",
    "\n",
    "                # Get results\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred')\n",
    "                results_obj['TPR'] = [TPR]\n",
    "                results_obj['FPR'] = [FPR]\n",
    "                results_obj['accuracy'] = [accuracy]\n",
    "\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_FPR_005')\n",
    "                results_obj['TPR_005'] = [TPR]\n",
    "                results_obj['FPR_005'] = [FPR]\n",
    "                results_obj['accuracy_005'] = [accuracy]\n",
    "\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_optimal_acc')\n",
    "                results_obj['TPR_optimal_acc'] = [TPR]\n",
    "                results_obj['FPR_optimal_acc'] = [FPR]\n",
    "                results_obj['accuracy_optimal_acc'] = [accuracy]\n",
    "                \n",
    "                # Get thresholds Min p value\n",
    "                dist_type = 'minus_log_min_p_value'\n",
    "                best_Threshold_minp, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=None)\n",
    "                results_obj['best_Threshold_minp'] = [best_Threshold_minp]\n",
    "                results_obj['AUC_ROC_minp'] = [auc_roc]\n",
    "\n",
    "                best_Threshold_minp_005, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=0.05)\n",
    "                results_obj['best_Threshold_minp_005'] = [best_Threshold_minp_005]\n",
    "                results_obj['AUC_ROC_005_minp'] = [auc_roc]\n",
    "\n",
    "                best_Threshold_minp_optimal_acc, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=-1)\n",
    "                results_obj['best_Threshold_minp_optimal_acc'] = [best_Threshold_minp_optimal_acc]\n",
    "                results_obj['AUC_ROC_optimal_acc_minp'] = [auc_roc]\n",
    "\n",
    "                # Use threshold\n",
    "                df['pred_minp'] = df['minus_log_min_p_value'].apply(lambda x: 1 if x >= best_Threshold_HC else 0)\n",
    "                df['pred_FPR_005_minp'] = df['minus_log_min_p_value'].apply(lambda x: 1 if x >= best_Threshold_HC_005 else 0)\n",
    "                df['pred_optimal_acc_minp'] = df['minus_log_min_p_value'].apply(lambda x: 1 if x >= best_Threshold_HC_optimal_acc else 0)\n",
    "\n",
    "                # Get results\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_minp')\n",
    "                results_obj['TPR_minp'] = [TPR]\n",
    "                results_obj['FPR_minp'] = [FPR]\n",
    "                results_obj['accuracy_minp'] = [accuracy]\n",
    "\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_FPR_005_minp')\n",
    "                results_obj['TPR_005_minp'] = [TPR]\n",
    "                results_obj['FPR_005_minp'] = [FPR]\n",
    "                results_obj['accuracy_005_minp'] = [accuracy]\n",
    "\n",
    "                TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_optimal_acc_minp')\n",
    "                results_obj['TPR_optimal_acc_minp'] = [TPR]\n",
    "                results_obj['FPR_optimal_acc_minp'] = [FPR]\n",
    "                results_obj['accuracy_optimal_acc_minp'] = [accuracy]\n",
    "\n",
    "                results_df = pd.concat([results_df, pd.DataFrame(results_obj)])\n",
    "\n",
    "        results_df.reset_index(drop=True)\n",
    "        results_df.to_csv(f'{files_path}\\\\folds_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60eb0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results csv combined folds. Avarge the reuslts\n",
    "# Cross validation for mainDataset folds\n",
    "# Maindataset Test results\n",
    "edit_ratios = [0.05, 0.1, 0.15]\n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles']\n",
    "models_names = ['gpt2xl', 'phi2']\n",
    "df_folds = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\folds_resutls.csv')\n",
    "\n",
    "results_df = pd.DataFrame(columns=['topic', 'model', 'edit_ratio'\n",
    "                                           , 'avg_Threshold_HC', 'AUC_ROC', 'TPR', 'FPR', 'accuracy'\n",
    "                                           , 'avg_Threshold_HC_005', 'AUC_ROC_005', 'TPR_005', 'FPR_005', 'accuracy_005'\n",
    "                                           , 'avg_Threshold_HC_optimal_acc', 'AUC_ROC_optimal_acc', 'TPR_optimal_acc'\n",
    "                                           , 'FPR_optimal_acc', 'accuracy_optimal_acc'\n",
    "                                           , 'avg_Threshold_minp', 'AUC_ROC_minp', 'TPR_minp', 'FPR_minp', 'accuracy_minp'\n",
    "                                           , 'avg_Threshold_minp_005', 'AUC_ROC_005_minp', 'TPR_005_minp', 'FPR_005_minp', 'accuracy_005_minp'\n",
    "                                           , 'avg_Threshold_minp_optimal_acc', 'AUC_ROC_optimal_acc_minp', 'TPR_optimal_acc_minp'\n",
    "                                           , 'FPR_optimal_acc_minp', 'accuracy_optimal_acc_minp'])\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation\\\\{topic}\\\\edit_ratio_{edit_ratio}'\n",
    "        df = None\n",
    "        \n",
    "\n",
    "        for model_name in models_names:\n",
    "            df_current_results = df_folds[(df_folds['topic']==topic) & (df_folds['edit_ratio']==edit_ratio) & (df_folds['model']==model_name)]\n",
    "            \n",
    "            # Init\n",
    "            results_folder = 'results_phi2' if model_name == 'phi2' else 'results'\n",
    "            results_folder = f'{files_path}\\\\{results_folder}'\n",
    "            results_obj = {\n",
    "                'topic': [topic],\n",
    "                'model': [model_name],\n",
    "                'edit_ratio': [edit_ratio]\n",
    "            }\n",
    "\n",
    "            # Get results files\n",
    "            files = glob.glob(f'{results_folder}/*_results.csv')\n",
    "            for file in files:\n",
    "                if df is None:\n",
    "                    df = pd.read_csv(file)\n",
    "                else:\n",
    "                    df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "            df['edited'] = df['Unnamed: 0'].apply(lambda x: 1 if 'edited' in x else 0)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            # Get thresholds HC\n",
    "            dist_type = 'HC'\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=None)\n",
    "            avg_Threshold_HC = df_current_results['best_Threshold_HC'].mean()\n",
    "            results_obj['avg_Threshold_HC'] = [avg_Threshold_HC]\n",
    "            results_obj['AUC_ROC'] = [auc_roc]\n",
    "\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=0.05)\n",
    "            avg_Threshold_HC_005 = df_current_results['best_Threshold_HC_005'].mean()\n",
    "            results_obj['avg_Threshold_HC_005'] = [avg_Threshold_HC_005]\n",
    "            results_obj['AUC_ROC_005'] = [auc_roc]\n",
    "\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=-1)\n",
    "            avg_Threshold_HC_optimal_acc = df_current_results['best_Threshold_HC_optimal_acc'].mean()\n",
    "            results_obj['avg_Threshold_HC_optimal_acc'] = [avg_Threshold_HC_optimal_acc]\n",
    "            results_obj['AUC_ROC_optimal_acc'] = [auc_roc]\n",
    "\n",
    "            # Use threshold\n",
    "            df['pred'] = df['HC'].apply(lambda x: 1 if x >= avg_Threshold_HC else 0)\n",
    "            df['pred_FPR_005'] = df['HC'].apply(lambda x: 1 if x >= avg_Threshold_HC_005 else 0)\n",
    "            df['pred_optimal_acc'] = df['HC'].apply(lambda x: 1 if x >= avg_Threshold_HC_optimal_acc else 0)\n",
    "\n",
    "            # Get results\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred')\n",
    "            results_obj['TPR'] = [TPR]\n",
    "            results_obj['FPR'] = [FPR]\n",
    "            results_obj['accuracy'] = [accuracy]\n",
    "\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_FPR_005')\n",
    "            results_obj['TPR_005'] = [TPR]\n",
    "            results_obj['FPR_005'] = [FPR]\n",
    "            results_obj['accuracy_005'] = [accuracy]\n",
    "\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_optimal_acc')\n",
    "            results_obj['TPR_optimal_acc'] = [TPR]\n",
    "            results_obj['FPR_optimal_acc'] = [FPR]\n",
    "            results_obj['accuracy_optimal_acc'] = [accuracy]\n",
    "            \n",
    "            # Get thresholds Min P value\n",
    "            dist_type = 'minus_log_min_p_value'\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=None)\n",
    "            avg_Threshold_minp = df_current_results['best_Threshold_minp'].mean()\n",
    "            results_obj['avg_Threshold_minp'] = [avg_Threshold_minp]\n",
    "            results_obj['AUC_ROC_minp'] = [auc_roc]\n",
    "\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=0.05)\n",
    "            avg_Threshold_minp_005 = df_current_results['best_Threshold_minp_005'].mean()\n",
    "            results_obj['avg_Threshold_minp_005'] = [avg_Threshold_minp_005]\n",
    "            results_obj['AUC_ROC_005_minp'] = [auc_roc]\n",
    "\n",
    "            _, auc_roc = check_AUC_ROC(df, dist_type=dist_type, show_plot=False, threshold_FPR_at=-1)\n",
    "            avg_Threshold_minp_optimal_acc = df_current_results['best_Threshold_minp_optimal_acc'].mean()\n",
    "            results_obj['avg_Threshold_minp_optimal_acc'] = [avg_Threshold_minp_optimal_acc]\n",
    "            results_obj['AUC_ROC_optimal_acc_minp'] = [auc_roc]\n",
    "\n",
    "            # Use threshold\n",
    "            df['pred_minp'] = df[dist_type].apply(lambda x: 1 if x >= avg_Threshold_minp else 0)\n",
    "            df['pred_FPR_005_minp'] = df[dist_type].apply(lambda x: 1 if x >= avg_Threshold_minp_005 else 0)\n",
    "            df['pred_optimal_acc_minp'] = df[dist_type].apply(lambda x: 1 if x >= avg_Threshold_minp_optimal_acc else 0)\n",
    "\n",
    "            # Get results\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_minp')\n",
    "            results_obj['TPR_minp'] = [TPR]\n",
    "            results_obj['FPR_minp'] = [FPR]\n",
    "            results_obj['accuracy_minp'] = [accuracy]\n",
    "\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_FPR_005_minp')\n",
    "            results_obj['TPR_005_minp'] = [TPR]\n",
    "            results_obj['FPR_005_minp'] = [FPR]\n",
    "            results_obj['accuracy_005_minp'] = [accuracy]\n",
    "\n",
    "            TPR, FPR, accuracy = calc_metrics(df, 'edited', 'pred_optimal_acc_minp')\n",
    "            results_obj['TPR_optimal_acc_minp'] = [TPR]\n",
    "            results_obj['FPR_optimal_acc_minp'] = [FPR]\n",
    "            results_obj['accuracy_optimal_acc_minp'] = [accuracy]\n",
    "\n",
    "            results_df = pd.concat([results_df, pd.DataFrame(results_obj)])\n",
    "\n",
    "        results_df = results_df.reset_index(drop=True)\n",
    "        results_df.to_csv('mainDataset_cross_validation_test_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c287bfe1",
   "metadata": {},
   "source": [
    "#### **Power analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554970cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_files(articles_folder, orignal_article=True):\n",
    "    \n",
    "    file_type = 'original' if orignal_article else 'edited'\n",
    "    \n",
    "    # Get results files\n",
    "    files_original = glob.glob(f'{articles_folder}/*_{file_type}_results.csv')\n",
    "    files_original += glob.glob(f'{articles_folder}\\\\test/*_{file_type}_results.csv')\n",
    "    df_lst = []\n",
    "    for file in files_original:\n",
    "        df_lst.append(pd.read_csv(file))\n",
    "      \n",
    "    df = pd.concat(df_lst, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_threshold(df, statistics_type, threhsold_jumps=0.1):\n",
    "    y_test = [0 for i in range(len(df))]\n",
    "    \n",
    "    # Get thresholds options\n",
    "    min_stats = math.floor(df[statistics_type].min())\n",
    "    max_stats = math.ceil(df[statistics_type].max())\n",
    "    thresholds = [i for i in np.arange(min_stats, max_stats, threhsold_jumps)]\n",
    "    \n",
    "    # For each threshold\n",
    "    for threshold in thresholds:\n",
    "        pred = df[statistics_type].apply(lambda x: 1 if x > threshold else 0) # Use it\n",
    "\n",
    "        # Calculate FPR\n",
    "        FP = len(pred[pred==1])\n",
    "        TN = len(pred[pred==0])\n",
    "        FPR = FP / (FP + TN)\n",
    "        \n",
    "        # If FP @ 0.05\n",
    "        if FPR <= 0.05:\n",
    "            return threshold\n",
    "        \n",
    "    return -1\n",
    "\n",
    "def calc_metrics_power_analysis(pred):\n",
    "    TP = len(pred[pred==1])\n",
    "    FN = len(pred[pred==0])\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "\n",
    "    TPR = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    return TPR, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1b8fbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv results for all topics\n",
    "files_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Cross_validation'\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "num_of_sentences = [50, 100, 200]\n",
    "edits_ratios = [0.1, 0.2]\n",
    "models_names = ['gpt2xl', 'phi2']\n",
    "statistics_types = ['HC', 'minus_log_min_p_value']\n",
    "\n",
    "df_results = pd.DataFrame(columns=['topic', '#Sentences', 'model', 'statistics', 'edit_ratio', 'threshold_at_FPR_005', 'TPR_at_FPR_005', 'Accuracy_at_FPR_005'])\n",
    "\n",
    "for topic in topics:\n",
    "    for sentences in num_of_sentences:\n",
    "        for edit_ratio in edits_ratios:\n",
    "            for model_name in models_names:\n",
    "                for statistics in statistics_types:\n",
    "                    TPR_lst = []\n",
    "                    accuracy_lst = []\n",
    "                    threshold_lst = []\n",
    "                    for fold in range(10):\n",
    "                        # Get data\n",
    "                        test_folder = 'results' if model_name == 'gpt2xl' else 'results_phi2'\n",
    "                        articles_folder = f'{files_path}\\\\{topic}\\\\{sentences}_sentences\\\\{edit_ratio}\\\\fold_{fold}'\n",
    "                        df_original = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=True)\n",
    "                        df_edited = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=False)\n",
    "\n",
    "                        # Calculate thresholds and predictions\n",
    "                        threshold = get_threshold(df_original, statistics)\n",
    "                        pred = df_edited[statistics].apply(lambda x: 1 if x > threshold else 0)\n",
    "                        TPR, accuracy = calc_metrics_power_analysis(pred)\n",
    "                        TPR_lst.append(TPR)\n",
    "                        accuracy_lst.append(accuracy)\n",
    "                        threshold_lst.append(threshold)\n",
    "\n",
    "                    # Mean and STD\n",
    "                    TPR = np.array(TPR_lst).mean()\n",
    "                    TPR_std = np.array(TPR_lst).std()\n",
    "                    \n",
    "                    accuracy = np.array(accuracy_lst).mean()\n",
    "                    accuracy_std = np.array(accuracy_lst).std()\n",
    "                    \n",
    "                    threshold = np.array(threshold_lst).mean()\n",
    "                    \n",
    "                    # Save results\n",
    "                    results_obj = {\n",
    "                        'topic': [topic],\n",
    "                        '#Sentences': [sentences],\n",
    "                        'model': [model_name],\n",
    "                        'statistics': [statistics],\n",
    "                        'edit_ratio': [edit_ratio],\n",
    "                        'threshold_at_FPR_005': [threshold],\n",
    "                        'TPR_at_FPR_005': [TPR], \n",
    "                        'Accuracy_at_FPR_005': [accuracy],\n",
    "                        'TPR_at_FPR_005_std': [TPR_std], \n",
    "                        'Accuracy_at_FPR_005_std': [accuracy_std]\n",
    "                    }\n",
    "\n",
    "                    df_results = pd.concat([df_results, pd.DataFrame(results_obj)])\n",
    "df_results.to_csv('secondDataset_power_ananalysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f098bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv results for all topics by fold\n",
    "files_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\SecondDataset\\\\Cross_validation'\n",
    "topics = ['AbstractDataset', 'NewsDataset', 'WikiDataset']\n",
    "num_of_sentences = [50, 100, 200]\n",
    "edits_ratios = [0.1, 0.2]\n",
    "models_names = ['gpt2xl', 'phi2']\n",
    "statistics_types = ['HC', 'minus_log_min_p_value']\n",
    "\n",
    "df_results = pd.DataFrame(columns=['topic', '#Sentences', 'model', 'fold', 'statistics', 'edit_ratio', 'threshold_at_FPR_005', 'TPR_at_FPR_005', 'Accuracy_at_FPR_005'])\n",
    "\n",
    "for topic in topics:\n",
    "    for sentences in num_of_sentences:\n",
    "        for edit_ratio in edits_ratios:\n",
    "            for model_name in models_names:\n",
    "                for statistics in statistics_types:\n",
    "                    for fold in range(10):\n",
    "                        # Get data\n",
    "                        test_folder = 'results' if model_name == 'gpt2xl' else 'results_phi2'\n",
    "                        articles_folder = f'{files_path}\\\\{topic}\\\\{sentences}_sentences\\\\{edit_ratio}\\\\fold_{fold}'\n",
    "                        df_original = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=True)\n",
    "                        df_edited = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=False)\n",
    "\n",
    "                        # Calculate thresholds and predictions\n",
    "                        threshold = get_threshold(df_original, statistics)\n",
    "                        pred = df_edited[statistics].apply(lambda x: 1 if x > threshold else 0)\n",
    "                        TPR, accuracy = calc_metrics_power_analysis(pred)\n",
    "\n",
    "                        # Save results\n",
    "                        results_obj = {\n",
    "                            'topic': [topic],\n",
    "                            '#Sentences': [sentences],\n",
    "                            'model': [model_name],\n",
    "                            'fold': [fold],\n",
    "                            'statistics': [statistics],\n",
    "                            'edit_ratio': [edit_ratio],\n",
    "                            'threshold_at_FPR_005': [threshold],\n",
    "                            'TPR_at_FPR_005': [TPR], \n",
    "                            'Accuracy_at_FPR_005': [accuracy],\n",
    "                        }\n",
    "\n",
    "                        df_results = pd.concat([df_results, pd.DataFrame(results_obj)])\n",
    "df_results.to_csv('secondDataset_power_ananalysis_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adeae155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all article results to get the min p value csv\n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles']\n",
    "edits_ratios = [0.05, 0.1, 0.15]\n",
    "models = ['gpt2xl', 'phi2']\n",
    "columns=['topic', 'model', 'fold', 'edited', 'edit_ratio', 'length', 'HC', 'minus_log_min_p_value']\n",
    "\n",
    "df_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edits_ratios:\n",
    "        for model in models:\n",
    "            for fold in range(10):\n",
    "                files_path = f'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation'\n",
    "                test_folder = 'results' if model == 'gpt2xl' else 'results_phi2'\n",
    "                articles_folder = f'{files_path}\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\fold_{fold}'\n",
    "                df_original = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=True)\n",
    "                df_edited = get_results_files(f'{articles_folder}\\\\{test_folder}', orignal_article=False)\n",
    "\n",
    "                df_original['topic'] = topic\n",
    "                df_original['model'] = model\n",
    "                df_original['fold'] = fold\n",
    "                df_original['edit_ratio'] = edit_ratio\n",
    "                df_original['edited'] = 0\n",
    "                df_original = df_original[df_original['length']>=50]\n",
    "                \n",
    "                df_edited['topic'] = topic\n",
    "                df_edited['model'] = model\n",
    "                df_edited['fold'] = fold\n",
    "                df_edited['edit_ratio'] = edit_ratio\n",
    "                df_edited['edited'] = 1\n",
    "                df_edited = df_edited[df_edited['length']>=50]\n",
    "                \n",
    "                df_results = pd.concat([df_results, df_original[columns], df_edited[columns]], ignore_index=True)\n",
    "\n",
    "df_results.to_csv('mainDataset_minp_value_folds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df936a19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Combine all articles and results for main dataset Cross Validation\n",
    "edit_ratios = [0.05, 0.1, 0.15]\n",
    "topics = ['characters_articles', 'locations_articles', 'nature_articles', 'video_games_series_movies_articles', 'war_articles']\n",
    "models_names = ['gpt2xl', 'phi2']\n",
    "df_results = pd.read_csv('D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\folds_resutls.csv')\n",
    "\n",
    "columns = ['Unnamed: 0', 'topic', 'model', 'edit_ratio', 'fold', 'HC', 'length', 'edited', 'minus_log_min_p_value', 'best_Threshold_HC', 'best_Threshold_HC_005', 'best_Threshold_minp', 'best_Threshold_minp_005', 'pred_HC', 'pred_HC_005', 'pred_minp', 'pred_minp_005']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "files_path = 'D:\\\\.Idan\\\\תואר שני\\\\תזה\\\\mainDataset\\\\generatedArticles\\\\Cross_validation'\n",
    "\n",
    "for topic in topics:\n",
    "    for edit_ratio in edit_ratios:\n",
    "        for model_name in models_names:\n",
    "            for fold in range(10):\n",
    "                \n",
    "                # Get fold results\n",
    "                df_current_results = df_results[(df_results['topic']==topic) & (df_results['model']==model_name) \n",
    "                                                & (df_results['edit_ratio']==edit_ratio) & (df_results['fold']==fold)]\n",
    "                \n",
    "                best_Threshold_HC = df_current_results['best_Threshold_HC'].values[0]\n",
    "                best_Threshold_HC_005 = df_current_results['best_Threshold_HC_005'].values[0]\n",
    "                best_Threshold_minp = df_current_results['best_Threshold_minp'].values[0]\n",
    "                best_Threshold_minp_005 = df_current_results['best_Threshold_minp_005'].values[0]\n",
    "                \n",
    "                results_folder = 'results' if model_name == 'gpt2xl' else 'results_phi2'\n",
    "                files = glob.glob(f'{files_path}\\\\{topic}\\\\edit_ratio_{edit_ratio}\\\\fold_{fold}\\\\{results_folder}/*_results.csv')\n",
    "                for file in files:\n",
    "                    df_article = pd.read_csv(file)\n",
    "                    edited = int('edited_' in file)\n",
    "                    pred_HC = int((df_article['HC'].values > best_Threshold_HC))\n",
    "                    pred_HC_005 = int((df_article['HC'].values > best_Threshold_HC_005))\n",
    "                    pred_minp = int((df_article['minus_log_min_p_value'].values > best_Threshold_minp))\n",
    "                    pred_minp_005 = int((df_article['minus_log_min_p_value'].values > best_Threshold_minp_005))\n",
    "                    \n",
    "                    article_obj = {\n",
    "                        'Unnamed: 0': df_article['Unnamed: 0'].values, \n",
    "                        'topic': [topic], \n",
    "                        'model': [model_name], \n",
    "                        'edit_ratio': df_article['edit_rate'].values, \n",
    "                        'fold': [fold], \n",
    "                        'HC': df_article['HC'].values, \n",
    "                        'length': df_article['length'].values, \n",
    "                        'edited': [edited], \n",
    "                        'minus_log_min_p_value': df_article['minus_log_min_p_value'].values, \n",
    "                        'best_Threshold_HC': [best_Threshold_HC], \n",
    "                        'best_Threshold_HC_005': [best_Threshold_HC_005], \n",
    "                        'best_Threshold_minp': [best_Threshold_minp], \n",
    "                        'best_Threshold_minp_005': [best_Threshold_minp_005], \n",
    "                        'pred_HC': [pred_HC], \n",
    "                        'pred_HC_005': [pred_HC_005], \n",
    "                        'pred_minp': [pred_minp], \n",
    "                        'pred_minp_005': [pred_minp_005]\n",
    "                    }\n",
    "                    \n",
    "                    df = pd.concat([df, pd.DataFrame(article_obj)], ignore_index=True)\n",
    "            \n",
    "df.to_csv('all_articles_results_maindataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
